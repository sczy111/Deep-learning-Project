{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffd5c52e-3739-436b-a7a6-3ffb7d9dc634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82195319-7f50-444a-9fa0-e1ba03664797",
   "metadata": {},
   "source": [
    "## Task 1 Transfer Learning \n",
    "\n",
    "The section below contains  the core utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af951e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Dataset preparation\n",
    "# ========================\n",
    "class RetinaMultiLabelDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        img_path = os.path.join(self.image_dir, row.iloc[0])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        labels = torch.tensor(row[1:].values.astype(\"float32\"))\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, labels\n",
    "\n",
    "class RetinaTestDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_dir, transform=None):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        self.ids = df.iloc[:, 0].values  # first column -> id/ID\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.ids[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_id)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, img_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79bf3dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# build model\n",
    "# ========================\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "\n",
    "def build_model(backbone=\"resnet18\", num_classes=3, pretrained=True):\n",
    "    if backbone == \"resnet18\":\n",
    "        weights = ResNet18_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "        model = resnet18(weights=weights)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "    elif backbone == \"efficientnet\":\n",
    "        weights = EfficientNet_B0_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "        model = efficientnet_b0(weights=weights)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported backbone\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "747e2295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# model training and val\n",
    "# ========================\n",
    "def train_one_backbone(\n",
    "    backbone,\n",
    "    train_csv,\n",
    "    val_csv,\n",
    "    test_csv,\n",
    "    train_image_dir,\n",
    "    val_image_dir,\n",
    "    test_image_dir,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    lr=1e-4,\n",
    "    img_size=256,\n",
    "    save_dir=\"checkpoints\",\n",
    "    pretrained_backbone=None,\n",
    "    task=\"full_ft\",\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "\n",
    "    task_name_map = {\n",
    "        \"no_finetune\": \"Task1.1 No fine-tuning\",\n",
    "        \"cls_only\": \"Task1.2 Frozen backbone, classifier only\",\n",
    "        \"full_ft\": \"Task1.3 Full fine-tuning\",\n",
    "    }\n",
    "\n",
    "    print(\"===========================================\")\n",
    "    print(f\"{task_name_map[task]}  |  Backbone: {backbone}\")\n",
    "    print(\"===========================================\")\n",
    "\n",
    "    # transforms\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # datasets & dataloaders\n",
    "    train_ds = RetinaMultiLabelDataset(train_csv, train_image_dir, transform)\n",
    "    val_ds = RetinaMultiLabelDataset(val_csv, val_image_dir,transform)\n",
    "    test_ds = RetinaMultiLabelDataset(test_csv, test_image_dir, transform)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # compute pos_weight\n",
    "    label_cols = train_ds.data.columns[1:]  # skip ID\n",
    "    pos_counts = train_ds.data[label_cols].sum(axis=0).values.astype(np.float32)\n",
    "    neg_counts = len(train_ds) - pos_counts\n",
    "    pos_weight_np = neg_counts / (pos_counts + 1e-6)  # avoid division by zero\n",
    "\n",
    "    pos_weight = torch.tensor(pos_weight_np, dtype=torch.float32, device=device)\n",
    "    print(\"pos_weight:\", pos_weight)\n",
    "\n",
    "\n",
    "    # model\n",
    "    model = build_model(backbone, num_classes=3, pretrained=False).to(device)\n",
    "\n",
    "    if pretrained_backbone is not None:\n",
    "        state_dict = torch.load(pretrained_backbone, map_location=\"cpu\")\n",
    "        model.load_state_dict(state_dict)\n",
    "        print(f\"Loaded pretrained weights from {pretrained_backbone}\")\n",
    "\n",
    "    # set which parameters are trainable\n",
    "    if task == \"no_finetune\":\n",
    "        # everything is frozen\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = False\n",
    "        optimizer = None\n",
    "    elif task == \"cls_only\":\n",
    "        # freeze backbone\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = False\n",
    "        # unfreeze classifier\n",
    "        if backbone == \"resnet18\":\n",
    "            for p in model.fc.parameters():\n",
    "                p.requires_grad = True\n",
    "        elif backbone == \"efficientnet\":\n",
    "            for p in model.classifier.parameters():\n",
    "                p.requires_grad = True\n",
    "        optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "    else:  # full_ft\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = True\n",
    "        optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "        #scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3,)\n",
    "\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight = pos_weight)\n",
    "\n",
    "    # checkpoint path (unique per backbone + task)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    task_file_map = {\n",
    "    \"no_finetune\": \"task1_1\",\n",
    "    \"cls_only\":    \"task1_2\",\n",
    "    \"full_ft\":     \"task1_3\",\n",
    "    }\n",
    "    task_prefix = task_file_map[task] \n",
    "    ckpt_path = os.path.join(save_dir, f\"csu_{task_prefix}_{backbone}.pt\")\n",
    "\n",
    "    # ========= TRAINING (only for Task1.2 and Task1.3) =========\n",
    "    if task != \"no_finetune\":\n",
    "        best_val_loss = float(\"inf\")\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            for imgs, labels in train_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "            train_loss /= len(train_loader.dataset)\n",
    "\n",
    "            # validation\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for imgs, labels in val_loader:\n",
    "                    imgs, labels = imgs.to(device), labels.to(device)\n",
    "                    outputs = model(imgs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_loss += loss.item() * imgs.size(0)\n",
    "            val_loss /= len(val_loader.dataset)\n",
    "            #scheduler.step(val_loss)\n",
    "\n",
    "            print(f\"[{backbone}] Epoch {epoch+1}/{epochs} Train Loss: {train_loss:.4f} Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "            # save best\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                torch.save(model.state_dict(), ckpt_path)\n",
    "                print(f\"Saved best model for {backbone} ({task}) at {ckpt_path}\")\n",
    "    else:\n",
    "        # Task1.1: no fine-tuning â€“ directly evaluate the pretrained model\n",
    "        torch.save(model.state_dict(), ckpt_path)\n",
    "        print(f\"[{backbone}] {task_name_map[task]}: no training, model saved at {ckpt_path}\")\n",
    "\n",
    "    # ========= OFFSITE TEST EVALUATION =========\n",
    "    model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in test_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            outputs = model(imgs)\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "            preds = (probs > 0.5).astype(int)\n",
    "            y_true.extend(labels.numpy())\n",
    "            y_pred.extend(preds)\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    return ckpt_path, y_true, y_pred  # used later for Kaggle submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0086b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to generate submission for kaggle\n",
    "def generate_kaggle_submission(\n",
    "    backbone,\n",
    "    ckpt_path,\n",
    "    onsite_csv,\n",
    "    onsite_image_dir,\n",
    "    img_size=256,\n",
    "    batch_size=32,\n",
    "    out_csv=\"submission.csv\",\n",
    "    threshold=0.5,\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # build model and load weights\n",
    "    model = build_model(backbone, num_classes=3, pretrained=False).to(device)\n",
    "    model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    # read the original Kaggle template\n",
    "    template = pd.read_csv(onsite_csv)\n",
    "    id_col_name = template.columns[0]  # should be 'id'\n",
    "\n",
    "    # dataset and loader use the same csv for IDs\n",
    "    test_ds = RetinaTestDataset(onsite_csv, onsite_image_dir, transform)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    ids = []\n",
    "    probs_all = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, img_ids in test_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            outputs = model(imgs)\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy() \n",
    "            ids.extend(img_ids)\n",
    "            probs_all.append(probs)\n",
    "\n",
    "    probs_all = np.concatenate(probs_all, axis=0)\n",
    "\n",
    "    template_ids = template[id_col_name].values\n",
    "    ids = np.array(ids)\n",
    "\n",
    "    if not np.array_equal(template_ids, ids):\n",
    "        print(\"WARNING: IDs in template and predictions do not match exactly in order!\")\n",
    "        id_to_idx = {image_id: i for i, image_id in enumerate(ids)}\n",
    "        reorder_idx = [id_to_idx[x] for x in template_ids]\n",
    "        probs_all = probs_all[reorder_idx, :]\n",
    "\n",
    "    # convert probabilities to 0/1 labels using threshold\n",
    "    bin_preds = (probs_all >= threshold).astype(int)  # int64 by default\n",
    "\n",
    "    # overwrite D/G/A in template; keeps int dtypes and exact structure\n",
    "    template[\"D\"] = bin_preds[:, 0]\n",
    "    template[\"G\"] = bin_preds[:, 1]\n",
    "    template[\"A\"] = bin_preds[:, 2]\n",
    "\n",
    "    # ensure output directory exists\n",
    "    out_dir = \"submission\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out_path = os.path.join(out_dir, out_csv)\n",
    "    tmp_path = out_path + \".tmp\"\n",
    "    template.to_csv(tmp_path, index=False)\n",
    "    os.replace(tmp_path, out_path)\n",
    "\n",
    "    print(f\"Kaggle submission saved to: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb90d0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the evaluating metrics on offsite data\n",
    "def evaluating_metrics(y_true, y_pred, backbone, task_name,split_name):\n",
    "    \n",
    "    disease_names = [\"DR\", \"Glaucoma\", \"AMD\"]\n",
    "    rows = []\n",
    "    f1_list = []\n",
    "\n",
    "    print(f\"\\n{split_name.upper()} test results for {backbone} - {task_name}\")\n",
    "\n",
    "    for i, disease in enumerate(disease_names):\n",
    "        yt = y_true[:, i]\n",
    "        yp = y_pred[:, i]\n",
    "\n",
    "        acc = accuracy_score(yt, yp)\n",
    "        precision = precision_score(yt, yp, zero_division=0)\n",
    "        recall = recall_score(yt, yp, zero_division=0)\n",
    "        f1 = f1_score(yt, yp, zero_division=0)\n",
    "        kappa = cohen_kappa_score(yt, yp)\n",
    "\n",
    "        f1_list.append(f1)\n",
    "\n",
    "        \"\"\"# print in the required format (optional)\n",
    "        print(f\"{disease} Results [{backbone}] ({split_name})\")\n",
    "        print(f\"Accuracy : {acc:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall   : {recall:.4f}\")\n",
    "        print(f\"F1-score : {f1:.4f}\")\n",
    "        print(f\"Kappa    : {kappa:.4f}\")\n",
    "        print(\"-----\")\"\"\"\n",
    "\n",
    "        rows.append({\n",
    "            \"Backbone\": backbone,\n",
    "            \"Task\": task_name,\n",
    "            \"Split\": split_name,\n",
    "            \"Disease\": disease,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"F1-score\": f1,\n",
    "            \"Kappa\": kappa,\n",
    "        })\n",
    "\n",
    "    avg_f1 = sum(f1_list) / len(f1_list)\n",
    "    print(f\"Average F1 over 3 diseases ({split_name}): {avg_f1:.4f}\\n\")\n",
    "\n",
    "    rows.append({\n",
    "        \"Backbone\": backbone,\n",
    "        \"Task\": task_name,\n",
    "        \"Split\": split_name,\n",
    "        \"Disease\": \"Average F1\",\n",
    "        \"Accuracy\": None,\n",
    "        \"Precision\": None,\n",
    "        \"Recall\": None,\n",
    "        \"F1-score\": avg_f1,\n",
    "        \"Kappa\": None,\n",
    "    })\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d590c53-4056-4d5b-b0a5-73c3bb41d95d",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "This section defines all dataset paths, pretrained backbone locations, and key training hyperparameters. Adjust these values to match your local setup before running the experiments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "790a056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration (edit paths here)\n",
    "\n",
    "\n",
    "# Labeled splits\n",
    "train_csv = \"train.csv\"\n",
    "val_csv = \"val.csv\"\n",
    "offsite_test_csv = \"offsite_test.csv\"\n",
    "\n",
    "train_img_dir = \"./images/train\"\n",
    "val_img_dir = \"./images/val\"\n",
    "offsite_img_dir = \"./images/offsite_test\"\n",
    "\n",
    "# unlabeled onsite test (for kaggle submission)\n",
    "onsite_csv = \"onsite_test_submission.csv\"\n",
    "onsite_img_dir = \"./images/onsite_test\"\n",
    "\n",
    "# optional: your own pretrained backbones\n",
    "pretrained_resnet18 = \"./pretrained_backbone/ckpt_resnet18_ep50.pt\"\n",
    "pretrained_efficient = \"./pretrained_backbone/ckpt_efficientnet_ep50.pt\"\n",
    "\n",
    "img_size = 256\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "lr = 1e-4\n",
    "save_dir = \"checkpoints\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51234d0-e66d-42d5-9fd8-76959930c346",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "This section includes all training runs used to generate the results presented in the report and submitted to Kaggle. The preliminary results and metrics shown here were used directly in the report, and the hyperparameters in the code match the exact configurations of the final experiments. Because training is stochastic, your results may not match mine exactly, but repeated runs should produce similar outcomes.\n",
    "\n",
    "\n",
    "Each task is organized into its own code block. For example:\n",
    "\n",
    "- `# Task 1.1  No fine-tuning, resnet18`  \n",
    "\n",
    "\n",
    "After running multiple trials, the best-performing configuration was selected for the final model and Kaggle submission. Your single run may not match the final score exactly, but repeated runs should produce similar performance, though the number of repeated runs maybe large. And you need to have enough VRAM as some of the configurations were using batch_size = 128.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6705aa0c-1ca1-4f05-92d5-9222563dc1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "===========================================\n",
      "Task1.1 No fine-tuning  |  Backbone: resnet18\n",
      "===========================================\n",
      "pos_weight: tensor([0.5474, 3.9080, 4.6338], device='cuda:0')\n",
      "Loaded pretrained weights from ./pretrained_backbone/ckpt_resnet18_ep50.pt\n",
      "[resnet18] Task1.1 No fine-tuning: no training, model saved at checkpoints\\csu_task1_1_resnet18.pt\n",
      "Kaggle submission saved to: submission\\submission_resnet18_task1_1.csv\n",
      "\n",
      "OFFSITE test results for resnet18 - no_finetune\n",
      "Average F1 over 3 diseases (offsite): 0.5126\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backbone</th>\n",
       "      <th>Task</th>\n",
       "      <th>Split</th>\n",
       "      <th>Disease</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet18</td>\n",
       "      <td>no_finetune</td>\n",
       "      <td>offsite</td>\n",
       "      <td>DR</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.717172</td>\n",
       "      <td>0.507143</td>\n",
       "      <td>0.594142</td>\n",
       "      <td>0.033865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resnet18</td>\n",
       "      <td>no_finetune</td>\n",
       "      <td>offsite</td>\n",
       "      <td>Glaucoma</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.516854</td>\n",
       "      <td>0.380403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resnet18</td>\n",
       "      <td>no_finetune</td>\n",
       "      <td>offsite</td>\n",
       "      <td>AMD</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.301887</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>0.321124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resnet18</td>\n",
       "      <td>no_finetune</td>\n",
       "      <td>offsite</td>\n",
       "      <td>Average F1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.512554</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Backbone         Task    Split     Disease  Accuracy  Precision    Recall  \\\n",
       "0  resnet18  no_finetune  offsite          DR     0.515   0.717172  0.507143   \n",
       "1  resnet18  no_finetune  offsite    Glaucoma     0.785   0.575000  0.469388   \n",
       "2  resnet18  no_finetune  offsite         AMD     0.785   0.301887  0.727273   \n",
       "3  resnet18  no_finetune  offsite  Average F1       NaN        NaN       NaN   \n",
       "\n",
       "   F1-score     Kappa  \n",
       "0  0.594142  0.033865  \n",
       "1  0.516854  0.380403  \n",
       "2  0.426667  0.321124  \n",
       "3  0.512554       NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 1.1 No fine-tuning, resnet18\n",
    "\n",
    "backbone = \"resnet18\" \n",
    "\n",
    "if backbone == \"resnet18\":\n",
    "    pretrained_path = pretrained_resnet18\n",
    "elif backbone == \"efficientnet\":\n",
    "    pretrained_path = pretrained_efficient\n",
    "else:\n",
    "    raise ValueError(\"unknown backbone\")\n",
    "\n",
    "#offsite\n",
    "\n",
    "ckpt_task11, y_true_offsite, y_pred_offsite = train_one_backbone(\n",
    "    backbone=backbone,\n",
    "    train_csv=train_csv,\n",
    "    val_csv=val_csv,\n",
    "    test_csv=offsite_test_csv,\n",
    "    train_image_dir=train_img_dir,\n",
    "    val_image_dir=val_img_dir,\n",
    "    test_image_dir=offsite_img_dir,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "    img_size=img_size,\n",
    "    save_dir=save_dir,\n",
    "    pretrained_backbone=pretrained_path,\n",
    "    task=\"no_finetune\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#onsite\n",
    "generate_kaggle_submission(\n",
    "    backbone=backbone,\n",
    "    ckpt_path=\"./pretrained_backbone/ckpt_resnet18_ep50.pt\",\n",
    "    onsite_csv=onsite_csv,          \n",
    "    onsite_image_dir=onsite_img_dir,\n",
    "    img_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    out_csv=f\"submission_{backbone}_task1_1.csv\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "df_offsite = evaluating_metrics(\n",
    "    y_true=y_true_offsite,\n",
    "    y_pred=y_pred_offsite,\n",
    "    backbone=backbone,\n",
    "    task_name=\"no_finetune\",\n",
    "    split_name=\"offsite\",\n",
    ")\n",
    "df_offsite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd7e198a-08eb-4039-8720-358df8847180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "===========================================\n",
      "Task1.1 No fine-tuning  |  Backbone: efficientnet\n",
      "===========================================\n",
      "pos_weight: tensor([0.5474, 3.9080, 4.6338], device='cuda:0')\n",
      "Loaded pretrained weights from ./pretrained_backbone/ckpt_efficientnet_ep50.pt\n",
      "[efficientnet] Task1.1 No fine-tuning: no training, model saved at checkpoints\\csu_task1_1_efficientnet.pt\n",
      "Kaggle submission saved to: submission\\submission_efficientnet_task1_1.csv\n",
      "\n",
      "OFFSITE test results for efficientnet - no_finetune\n",
      "Average F1 over 3 diseases (offsite): 0.5541\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backbone</th>\n",
       "      <th>Task</th>\n",
       "      <th>Split</th>\n",
       "      <th>Disease</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>efficientnet</td>\n",
       "      <td>no_finetune</td>\n",
       "      <td>offsite</td>\n",
       "      <td>DR</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.745902</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.694656</td>\n",
       "      <td>0.122807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>efficientnet</td>\n",
       "      <td>no_finetune</td>\n",
       "      <td>offsite</td>\n",
       "      <td>Glaucoma</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>0.594059</td>\n",
       "      <td>0.457097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>efficientnet</td>\n",
       "      <td>no_finetune</td>\n",
       "      <td>offsite</td>\n",
       "      <td>AMD</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.246377</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.373626</td>\n",
       "      <td>0.248219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>efficientnet</td>\n",
       "      <td>no_finetune</td>\n",
       "      <td>offsite</td>\n",
       "      <td>Average F1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.554114</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Backbone         Task    Split     Disease  Accuracy  Precision  \\\n",
       "0  efficientnet  no_finetune  offsite          DR     0.600   0.745902   \n",
       "1  efficientnet  no_finetune  offsite    Glaucoma     0.795   0.576923   \n",
       "2  efficientnet  no_finetune  offsite         AMD     0.715   0.246377   \n",
       "3  efficientnet  no_finetune  offsite  Average F1       NaN        NaN   \n",
       "\n",
       "     Recall  F1-score     Kappa  \n",
       "0  0.650000  0.694656  0.122807  \n",
       "1  0.612245  0.594059  0.457097  \n",
       "2  0.772727  0.373626  0.248219  \n",
       "3       NaN  0.554114       NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 1.1 No fine-tuning, efficientnet\n",
    "\n",
    "backbone = \"efficientnet\" \n",
    "\n",
    "if backbone == \"resnet18\":\n",
    "    pretrained_path = pretrained_resnet18\n",
    "elif backbone == \"efficientnet\":\n",
    "    pretrained_path = pretrained_efficient\n",
    "else:\n",
    "    raise ValueError(\"unknown backbone\")\n",
    "\n",
    "#offsite\n",
    "ckpt_task11, y_true_offsite, y_pred_offsite = train_one_backbone(\n",
    "    backbone=backbone,\n",
    "    train_csv=train_csv,\n",
    "    val_csv=val_csv,\n",
    "    test_csv=offsite_test_csv,\n",
    "    train_image_dir=train_img_dir,\n",
    "    val_image_dir=val_img_dir,\n",
    "    test_image_dir=offsite_img_dir,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "    img_size=img_size,\n",
    "    save_dir=save_dir,\n",
    "    pretrained_backbone=pretrained_path,\n",
    "    task=\"no_finetune\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#onsite\n",
    "generate_kaggle_submission(\n",
    "    backbone=backbone,\n",
    "    ckpt_path=ckpt_task11,\n",
    "    onsite_csv=onsite_csv,          \n",
    "    onsite_image_dir=onsite_img_dir,\n",
    "    img_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    out_csv=f\"submission_{backbone}_task1_1.csv\",\n",
    ")\n",
    "\n",
    "df_offsite = evaluating_metrics(\n",
    "    y_true=y_true_offsite,\n",
    "    y_pred=y_pred_offsite,\n",
    "    backbone=backbone,\n",
    "    task_name=\"no_finetune\",\n",
    "    split_name=\"offsite\",\n",
    ")\n",
    "df_offsite\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c217cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "===========================================\n",
      "Task1.2 Frozen backbone, classifier only  |  Backbone: resnet18\n",
      "===========================================\n",
      "pos_weight: tensor([0.5474, 3.9080, 4.6338], device='cuda:0')\n",
      "Loaded pretrained weights from ./pretrained_backbone/ckpt_resnet18_ep50.pt\n",
      "[resnet18] Epoch 1/30 Train Loss: 1.4870 Val Loss: 1.2051\n",
      "Saved best model for resnet18 (cls_only) at checkpoints\\csu_task1_2_resnet18.pt\n",
      "[resnet18] Epoch 2/30 Train Loss: 0.9486 Val Loss: 1.0159\n",
      "Saved best model for resnet18 (cls_only) at checkpoints\\csu_task1_2_resnet18.pt\n",
      "[resnet18] Epoch 3/30 Train Loss: 0.8306 Val Loss: 0.8817\n",
      "Saved best model for resnet18 (cls_only) at checkpoints\\csu_task1_2_resnet18.pt\n",
      "[resnet18] Epoch 4/30 Train Loss: 0.7812 Val Loss: 0.8367\n",
      "Saved best model for resnet18 (cls_only) at checkpoints\\csu_task1_2_resnet18.pt\n",
      "[resnet18] Epoch 5/30 Train Loss: 0.7701 Val Loss: 0.8403\n",
      "[resnet18] Epoch 6/30 Train Loss: 0.7545 Val Loss: 0.8191\n",
      "Saved best model for resnet18 (cls_only) at checkpoints\\csu_task1_2_resnet18.pt\n",
      "[resnet18] Epoch 7/30 Train Loss: 0.7451 Val Loss: 0.9038\n",
      "[resnet18] Epoch 8/30 Train Loss: 0.7409 Val Loss: 0.8326\n",
      "[resnet18] Epoch 9/30 Train Loss: 0.7380 Val Loss: 0.8199\n",
      "[resnet18] Epoch 10/30 Train Loss: 0.7416 Val Loss: 0.8007\n",
      "Saved best model for resnet18 (cls_only) at checkpoints\\csu_task1_2_resnet18.pt\n",
      "[resnet18] Epoch 11/30 Train Loss: 0.7208 Val Loss: 0.8089\n",
      "[resnet18] Epoch 12/30 Train Loss: 0.7266 Val Loss: 0.7974\n",
      "Saved best model for resnet18 (cls_only) at checkpoints\\csu_task1_2_resnet18.pt\n",
      "[resnet18] Epoch 13/30 Train Loss: 0.7195 Val Loss: 0.8068\n",
      "[resnet18] Epoch 14/30 Train Loss: 0.7187 Val Loss: 0.8225\n",
      "[resnet18] Epoch 15/30 Train Loss: 0.7169 Val Loss: 0.8021\n",
      "[resnet18] Epoch 16/30 Train Loss: 0.7060 Val Loss: 0.8108\n",
      "[resnet18] Epoch 17/30 Train Loss: 0.7166 Val Loss: 0.8218\n",
      "[resnet18] Epoch 18/30 Train Loss: 0.7225 Val Loss: 0.8650\n",
      "[resnet18] Epoch 19/30 Train Loss: 0.7065 Val Loss: 0.7762\n",
      "Saved best model for resnet18 (cls_only) at checkpoints\\csu_task1_2_resnet18.pt\n",
      "[resnet18] Epoch 20/30 Train Loss: 0.6871 Val Loss: 0.8071\n",
      "[resnet18] Epoch 21/30 Train Loss: 0.6888 Val Loss: 0.7609\n",
      "Saved best model for resnet18 (cls_only) at checkpoints\\csu_task1_2_resnet18.pt\n",
      "[resnet18] Epoch 22/30 Train Loss: 0.6847 Val Loss: 0.8029\n",
      "[resnet18] Epoch 23/30 Train Loss: 0.6945 Val Loss: 0.7598\n",
      "Saved best model for resnet18 (cls_only) at checkpoints\\csu_task1_2_resnet18.pt\n",
      "[resnet18] Epoch 24/30 Train Loss: 0.6940 Val Loss: 0.7667\n",
      "[resnet18] Epoch 25/30 Train Loss: 0.6880 Val Loss: 0.7609\n",
      "[resnet18] Epoch 26/30 Train Loss: 0.6806 Val Loss: 0.7782\n",
      "[resnet18] Epoch 27/30 Train Loss: 0.6802 Val Loss: 0.8117\n",
      "[resnet18] Epoch 28/30 Train Loss: 0.6805 Val Loss: 0.7855\n",
      "[resnet18] Epoch 29/30 Train Loss: 0.6801 Val Loss: 0.7874\n",
      "[resnet18] Epoch 30/30 Train Loss: 0.6680 Val Loss: 0.7572\n",
      "Saved best model for resnet18 (cls_only) at checkpoints\\csu_task1_2_resnet18.pt\n",
      "Kaggle submission saved to: submission\\submission_resnet18_task1_2.csv\n",
      "\n",
      "OFFSITE test results for resnet18 - cls_only\n",
      "Average F1 over 3 diseases (offsite): 0.6437\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backbone</th>\n",
       "      <th>Task</th>\n",
       "      <th>Split</th>\n",
       "      <th>Disease</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet18</td>\n",
       "      <td>cls_only</td>\n",
       "      <td>offsite</td>\n",
       "      <td>DR</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.845588</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.462617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resnet18</td>\n",
       "      <td>cls_only</td>\n",
       "      <td>offsite</td>\n",
       "      <td>Glaucoma</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.589286</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.497163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resnet18</td>\n",
       "      <td>cls_only</td>\n",
       "      <td>offsite</td>\n",
       "      <td>AMD</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.322034</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.469136</td>\n",
       "      <td>0.367833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resnet18</td>\n",
       "      <td>cls_only</td>\n",
       "      <td>offsite</td>\n",
       "      <td>Average F1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.643680</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Backbone      Task    Split     Disease  Accuracy  Precision    Recall  \\\n",
       "0  resnet18  cls_only  offsite          DR     0.770   0.845588  0.821429   \n",
       "1  resnet18  cls_only  offsite    Glaucoma     0.805   0.589286  0.673469   \n",
       "2  resnet18  cls_only  offsite         AMD     0.785   0.322034  0.863636   \n",
       "3  resnet18  cls_only  offsite  Average F1       NaN        NaN       NaN   \n",
       "\n",
       "   F1-score     Kappa  \n",
       "0  0.833333  0.462617  \n",
       "1  0.628571  0.497163  \n",
       "2  0.469136  0.367833  \n",
       "3  0.643680       NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 1.2 classfier only, resnet18\n",
    "\n",
    "backbone = \"resnet18\" \n",
    "\n",
    "if backbone == \"resnet18\":\n",
    "    pretrained_path = pretrained_resnet18\n",
    "elif backbone == \"efficientnet\":\n",
    "    pretrained_path = pretrained_efficient\n",
    "else:\n",
    "    raise ValueError(\"unknown backbone\")\n",
    "\n",
    "#offsite\n",
    "ckpt_task12, y_true_offsite, y_pred_offsite = train_one_backbone(\n",
    "    backbone=backbone,\n",
    "    train_csv=train_csv,\n",
    "    val_csv=val_csv,\n",
    "    test_csv=offsite_test_csv,\n",
    "    train_image_dir=train_img_dir,\n",
    "    val_image_dir=val_img_dir,\n",
    "    test_image_dir=offsite_img_dir,\n",
    "    epochs=30,\n",
    "    batch_size=batch_size,\n",
    "    lr=1e-3,\n",
    "    img_size=img_size,\n",
    "    save_dir=save_dir,\n",
    "    pretrained_backbone=pretrained_path,\n",
    "    task=\"cls_only\",\n",
    ")\n",
    "\n",
    "\n",
    "#onsite\n",
    "generate_kaggle_submission(\n",
    "    backbone=backbone,\n",
    "    ckpt_path=ckpt_task12,\n",
    "    onsite_csv=onsite_csv,          \n",
    "    onsite_image_dir=onsite_img_dir,\n",
    "    img_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    out_csv=f\"submission_{backbone}_task1_2.csv\",\n",
    ")\n",
    "\n",
    "df_offsite = evaluating_metrics(\n",
    "    y_true=y_true_offsite,\n",
    "    y_pred=y_pred_offsite,\n",
    "    backbone=backbone,\n",
    "    task_name=\"cls_only\",\n",
    "    split_name=\"offsite\",\n",
    ")\n",
    "torch.cuda.empty_cache()\n",
    "df_offsite\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8328f084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "===========================================\n",
      "Task1.2 Frozen backbone, classifier only  |  Backbone: efficientnet\n",
      "===========================================\n",
      "pos_weight: tensor([0.5474, 3.9080, 4.6338], device='cuda:0')\n",
      "Loaded pretrained weights from ./pretrained_backbone/ckpt_efficientnet_ep50.pt\n",
      "[efficientnet] Epoch 1/40 Train Loss: 1.0352 Val Loss: 0.9356\n",
      "Saved best model for efficientnet (cls_only) at checkpoints\\csu_task1_2_efficientnet.pt\n",
      "[efficientnet] Epoch 2/40 Train Loss: 0.6710 Val Loss: 0.7640\n",
      "Saved best model for efficientnet (cls_only) at checkpoints\\csu_task1_2_efficientnet.pt\n",
      "[efficientnet] Epoch 3/40 Train Loss: 0.6180 Val Loss: 0.7128\n",
      "Saved best model for efficientnet (cls_only) at checkpoints\\csu_task1_2_efficientnet.pt\n",
      "[efficientnet] Epoch 4/40 Train Loss: 0.6111 Val Loss: 0.8110\n",
      "[efficientnet] Epoch 5/40 Train Loss: 0.5995 Val Loss: 0.7528\n",
      "[efficientnet] Epoch 6/40 Train Loss: 0.5676 Val Loss: 0.7472\n",
      "[efficientnet] Epoch 7/40 Train Loss: 0.5559 Val Loss: 0.7321\n",
      "[efficientnet] Epoch 8/40 Train Loss: 0.5301 Val Loss: 0.7646\n",
      "[efficientnet] Epoch 9/40 Train Loss: 0.5270 Val Loss: 0.7111\n",
      "Saved best model for efficientnet (cls_only) at checkpoints\\csu_task1_2_efficientnet.pt\n",
      "[efficientnet] Epoch 10/40 Train Loss: 0.5353 Val Loss: 0.6950\n",
      "Saved best model for efficientnet (cls_only) at checkpoints\\csu_task1_2_efficientnet.pt\n",
      "[efficientnet] Epoch 11/40 Train Loss: 0.5087 Val Loss: 0.6671\n",
      "Saved best model for efficientnet (cls_only) at checkpoints\\csu_task1_2_efficientnet.pt\n",
      "[efficientnet] Epoch 12/40 Train Loss: 0.5010 Val Loss: 0.6654\n",
      "Saved best model for efficientnet (cls_only) at checkpoints\\csu_task1_2_efficientnet.pt\n",
      "[efficientnet] Epoch 13/40 Train Loss: 0.5025 Val Loss: 0.6945\n",
      "[efficientnet] Epoch 14/40 Train Loss: 0.4705 Val Loss: 0.6871\n",
      "[efficientnet] Epoch 15/40 Train Loss: 0.4792 Val Loss: 0.7332\n",
      "[efficientnet] Epoch 16/40 Train Loss: 0.4997 Val Loss: 0.7075\n",
      "[efficientnet] Epoch 17/40 Train Loss: 0.4971 Val Loss: 0.8064\n",
      "[efficientnet] Epoch 18/40 Train Loss: 0.4737 Val Loss: 0.7154\n",
      "[efficientnet] Epoch 19/40 Train Loss: 0.4953 Val Loss: 0.7503\n",
      "[efficientnet] Epoch 20/40 Train Loss: 0.4763 Val Loss: 0.6272\n",
      "Saved best model for efficientnet (cls_only) at checkpoints\\csu_task1_2_efficientnet.pt\n",
      "[efficientnet] Epoch 21/40 Train Loss: 0.4495 Val Loss: 0.6844\n",
      "[efficientnet] Epoch 22/40 Train Loss: 0.4332 Val Loss: 0.7274\n",
      "[efficientnet] Epoch 23/40 Train Loss: 0.4522 Val Loss: 0.6775\n",
      "[efficientnet] Epoch 24/40 Train Loss: 0.4561 Val Loss: 0.6745\n",
      "[efficientnet] Epoch 25/40 Train Loss: 0.4356 Val Loss: 0.7696\n",
      "[efficientnet] Epoch 26/40 Train Loss: 0.4565 Val Loss: 0.6661\n",
      "[efficientnet] Epoch 27/40 Train Loss: 0.4369 Val Loss: 0.6672\n",
      "[efficientnet] Epoch 28/40 Train Loss: 0.4261 Val Loss: 0.6747\n",
      "[efficientnet] Epoch 29/40 Train Loss: 0.4254 Val Loss: 0.6736\n",
      "[efficientnet] Epoch 30/40 Train Loss: 0.4168 Val Loss: 0.6494\n",
      "[efficientnet] Epoch 31/40 Train Loss: 0.4163 Val Loss: 0.6659\n",
      "[efficientnet] Epoch 32/40 Train Loss: 0.4507 Val Loss: 0.6696\n",
      "[efficientnet] Epoch 33/40 Train Loss: 0.4293 Val Loss: 0.6682\n",
      "[efficientnet] Epoch 34/40 Train Loss: 0.4262 Val Loss: 0.7211\n",
      "[efficientnet] Epoch 35/40 Train Loss: 0.4926 Val Loss: 0.6524\n",
      "[efficientnet] Epoch 36/40 Train Loss: 0.4561 Val Loss: 0.6466\n",
      "[efficientnet] Epoch 37/40 Train Loss: 0.4166 Val Loss: 0.6826\n",
      "[efficientnet] Epoch 38/40 Train Loss: 0.3991 Val Loss: 0.7127\n",
      "[efficientnet] Epoch 39/40 Train Loss: 0.3915 Val Loss: 0.6770\n",
      "[efficientnet] Epoch 40/40 Train Loss: 0.4031 Val Loss: 0.7271\n",
      "Kaggle submission saved to: submission\\submission_efficientnet_task1_2.csv\n",
      "\n",
      "OFFSITE test results for efficientnet - cls_only\n",
      "Average F1 over 3 diseases (offsite): 0.6616\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backbone</th>\n",
       "      <th>Task</th>\n",
       "      <th>Split</th>\n",
       "      <th>Disease</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>efficientnet</td>\n",
       "      <td>cls_only</td>\n",
       "      <td>offsite</td>\n",
       "      <td>DR</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.904348</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.815686</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>efficientnet</td>\n",
       "      <td>cls_only</td>\n",
       "      <td>offsite</td>\n",
       "      <td>Glaucoma</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.516249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>efficientnet</td>\n",
       "      <td>cls_only</td>\n",
       "      <td>offsite</td>\n",
       "      <td>AMD</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.520548</td>\n",
       "      <td>0.433474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>efficientnet</td>\n",
       "      <td>cls_only</td>\n",
       "      <td>offsite</td>\n",
       "      <td>Average F1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661628</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Backbone      Task    Split     Disease  Accuracy  Precision    Recall  \\\n",
       "0  efficientnet  cls_only  offsite          DR     0.765   0.904348  0.742857   \n",
       "1  efficientnet  cls_only  offsite    Glaucoma     0.805   0.580645  0.734694   \n",
       "2  efficientnet  cls_only  offsite         AMD     0.825   0.372549  0.863636   \n",
       "3  efficientnet  cls_only  offsite  Average F1       NaN        NaN       NaN   \n",
       "\n",
       "   F1-score     Kappa  \n",
       "0  0.815686  0.500000  \n",
       "1  0.648649  0.516249  \n",
       "2  0.520548  0.433474  \n",
       "3  0.661628       NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 1.2 classfier only, efficientnet\n",
    "\n",
    "backbone = \"efficientnet\"\n",
    "\n",
    "if backbone == \"resnet18\":\n",
    "    pretrained_path = pretrained_resnet18\n",
    "elif backbone == \"efficientnet\":\n",
    "    pretrained_path = pretrained_efficient\n",
    "else:\n",
    "    raise ValueError(\"unknown backbone\")\n",
    "\n",
    "#offsite\n",
    "ckpt_task12, y_true_offsite, y_pred_offsite = train_one_backbone(\n",
    "    backbone=backbone,\n",
    "    train_csv=train_csv,\n",
    "    val_csv=val_csv,\n",
    "    test_csv=offsite_test_csv,\n",
    "    train_image_dir=train_img_dir,\n",
    "    val_image_dir=val_img_dir,\n",
    "    test_image_dir=offsite_img_dir,\n",
    "    epochs=40,\n",
    "    batch_size=batch_size,\n",
    "    lr=2e-3,\n",
    "    img_size=img_size,\n",
    "    save_dir=save_dir,\n",
    "    pretrained_backbone=pretrained_path,\n",
    "    task=\"cls_only\",\n",
    ")\n",
    "\n",
    "\n",
    "#onsite\n",
    "generate_kaggle_submission(\n",
    "    backbone=backbone,\n",
    "    ckpt_path=ckpt_task12,\n",
    "    onsite_csv=onsite_csv,          \n",
    "    onsite_image_dir=onsite_img_dir,\n",
    "    img_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    out_csv=f\"submission_{backbone}_task1_2.csv\",\n",
    ")\n",
    "\n",
    "df_offsite = evaluating_metrics(\n",
    "    y_true=y_true_offsite,\n",
    "    y_pred=y_pred_offsite,\n",
    "    backbone=backbone,\n",
    "    task_name=\"cls_only\",\n",
    "    split_name=\"offsite\",\n",
    ")\n",
    "torch.cuda.empty_cache()\n",
    "df_offsite\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec3b2b7b-6dd9-465b-8cf2-b0e3bda65538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "===========================================\n",
      "Task1.3 Full fine-tuning  |  Backbone: resnet18\n",
      "===========================================\n",
      "pos_weight: tensor([0.5474, 3.9080, 4.6338], device='cuda:0')\n",
      "Loaded pretrained weights from ./pretrained_backbone/ckpt_resnet18_ep50.pt\n",
      "[resnet18] Epoch 1/20 Train Loss: 1.2749 Val Loss: 2.2040\n",
      "Saved best model for resnet18 (full_ft) at checkpoints\\csu_task1_3_resnet18.pt\n",
      "[resnet18] Epoch 2/20 Train Loss: 0.4850 Val Loss: 1.2188\n",
      "Saved best model for resnet18 (full_ft) at checkpoints\\csu_task1_3_resnet18.pt\n",
      "[resnet18] Epoch 3/20 Train Loss: 0.3119 Val Loss: 0.8805\n",
      "Saved best model for resnet18 (full_ft) at checkpoints\\csu_task1_3_resnet18.pt\n",
      "[resnet18] Epoch 4/20 Train Loss: 0.2031 Val Loss: 0.7935\n",
      "Saved best model for resnet18 (full_ft) at checkpoints\\csu_task1_3_resnet18.pt\n",
      "[resnet18] Epoch 5/20 Train Loss: 0.1312 Val Loss: 0.8016\n",
      "[resnet18] Epoch 6/20 Train Loss: 0.0837 Val Loss: 0.8398\n",
      "[resnet18] Epoch 7/20 Train Loss: 0.0546 Val Loss: 0.8304\n",
      "[resnet18] Epoch 8/20 Train Loss: 0.0342 Val Loss: 0.9042\n",
      "[resnet18] Epoch 9/20 Train Loss: 0.0245 Val Loss: 1.0249\n",
      "[resnet18] Epoch 10/20 Train Loss: 0.0179 Val Loss: 1.1317\n",
      "[resnet18] Epoch 11/20 Train Loss: 0.0142 Val Loss: 1.1377\n",
      "[resnet18] Epoch 12/20 Train Loss: 0.0113 Val Loss: 1.1960\n",
      "[resnet18] Epoch 13/20 Train Loss: 0.0097 Val Loss: 1.2327\n",
      "[resnet18] Epoch 14/20 Train Loss: 0.0080 Val Loss: 1.1970\n",
      "[resnet18] Epoch 15/20 Train Loss: 0.0063 Val Loss: 1.2314\n",
      "[resnet18] Epoch 16/20 Train Loss: 0.0059 Val Loss: 1.2528\n",
      "[resnet18] Epoch 17/20 Train Loss: 0.0052 Val Loss: 1.3179\n",
      "[resnet18] Epoch 18/20 Train Loss: 0.0055 Val Loss: 1.3282\n",
      "[resnet18] Epoch 19/20 Train Loss: 0.0054 Val Loss: 1.3334\n",
      "[resnet18] Epoch 20/20 Train Loss: 0.0057 Val Loss: 1.3599\n",
      "Kaggle submission saved to: submission\\submission_resnet18_task1_3.csv\n",
      "\n",
      "OFFSITE test results for resnet18 - full_ft\n",
      "Average F1 over 3 diseases (offsite): 0.7104\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backbone</th>\n",
       "      <th>Task</th>\n",
       "      <th>Split</th>\n",
       "      <th>Disease</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet18</td>\n",
       "      <td>full_ft</td>\n",
       "      <td>offsite</td>\n",
       "      <td>DR</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.859155</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.865248</td>\n",
       "      <td>0.543269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resnet18</td>\n",
       "      <td>full_ft</td>\n",
       "      <td>offsite</td>\n",
       "      <td>Glaucoma</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.694232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resnet18</td>\n",
       "      <td>full_ft</td>\n",
       "      <td>offsite</td>\n",
       "      <td>AMD</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.422918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resnet18</td>\n",
       "      <td>full_ft</td>\n",
       "      <td>offsite</td>\n",
       "      <td>Average F1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710402</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Backbone     Task    Split     Disease  Accuracy  Precision    Recall  \\\n",
       "0  resnet18  full_ft  offsite          DR      0.81   0.859155  0.871429   \n",
       "1  resnet18  full_ft  offsite    Glaucoma      0.89   0.800000  0.734694   \n",
       "2  resnet18  full_ft  offsite         AMD      0.86   0.411765  0.636364   \n",
       "3  resnet18  full_ft  offsite  Average F1       NaN        NaN       NaN   \n",
       "\n",
       "   F1-score     Kappa  \n",
       "0  0.865248  0.543269  \n",
       "1  0.765957  0.694232  \n",
       "2  0.500000  0.422918  \n",
       "3  0.710402       NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 1.3 full fine-tune, resnet18\n",
    "\n",
    "backbone = \"resnet18\" \n",
    "\n",
    "if backbone == \"resnet18\":\n",
    "    pretrained_path = pretrained_resnet18\n",
    "elif backbone == \"efficientnet\":\n",
    "    pretrained_path = pretrained_efficient\n",
    "else:\n",
    "    raise ValueError(\"unknown backbone\")\n",
    "\n",
    "#offsite\n",
    "ckpt_task13, y_true_offsite, y_pred_offsite = train_one_backbone(\n",
    "    backbone=backbone,\n",
    "    train_csv=train_csv,\n",
    "    val_csv=val_csv,\n",
    "    test_csv=offsite_test_csv,\n",
    "    train_image_dir=train_img_dir,\n",
    "    val_image_dir=val_img_dir,\n",
    "    test_image_dir=offsite_img_dir,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    lr=2e-4,\n",
    "    img_size=img_size,\n",
    "    save_dir=save_dir,\n",
    "    pretrained_backbone=pretrained_path,\n",
    "    task=\"full_ft\",\n",
    ")\n",
    "\n",
    "\n",
    "#onsite\n",
    "generate_kaggle_submission(\n",
    "    backbone=backbone,\n",
    "    ckpt_path=ckpt_task13,\n",
    "    onsite_csv=onsite_csv,          \n",
    "    onsite_image_dir=onsite_img_dir,\n",
    "    img_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    out_csv=f\"submission_{backbone}_task1_3.csv\",\n",
    ")\n",
    "\n",
    "df_offsite = evaluating_metrics(\n",
    "    y_true=y_true_offsite,\n",
    "    y_pred=y_pred_offsite,\n",
    "    backbone=backbone,\n",
    "    task_name=\"full_ft\",\n",
    "    split_name=\"offsite\",\n",
    ")\n",
    "torch.cuda.empty_cache()\n",
    "df_offsite\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d207cb5b-5886-4294-9f9f-07d2b00e3825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "===========================================\n",
      "Task1.3 Full fine-tuning  |  Backbone: efficientnet\n",
      "===========================================\n",
      "pos_weight: tensor([0.5474, 3.9080, 4.6338], device='cuda:0')\n",
      "Loaded pretrained weights from ./pretrained_backbone/ckpt_efficientnet_ep50.pt\n",
      "[efficientnet] Epoch 1/20 Train Loss: 1.2142 Val Loss: 1.0799\n",
      "Saved best model for efficientnet (full_ft) at checkpoints\\csu_task1_3_efficientnet.pt\n",
      "[efficientnet] Epoch 2/20 Train Loss: 0.4626 Val Loss: 0.9317\n",
      "Saved best model for efficientnet (full_ft) at checkpoints\\csu_task1_3_efficientnet.pt\n",
      "[efficientnet] Epoch 3/20 Train Loss: 0.2897 Val Loss: 0.9116\n",
      "Saved best model for efficientnet (full_ft) at checkpoints\\csu_task1_3_efficientnet.pt\n",
      "[efficientnet] Epoch 4/20 Train Loss: 0.1977 Val Loss: 0.8816\n",
      "Saved best model for efficientnet (full_ft) at checkpoints\\csu_task1_3_efficientnet.pt\n",
      "[efficientnet] Epoch 5/20 Train Loss: 0.1348 Val Loss: 1.0668\n",
      "[efficientnet] Epoch 6/20 Train Loss: 0.1017 Val Loss: 1.2950\n",
      "[efficientnet] Epoch 7/20 Train Loss: 0.0745 Val Loss: 1.3140\n",
      "[efficientnet] Epoch 8/20 Train Loss: 0.0545 Val Loss: 1.2507\n",
      "[efficientnet] Epoch 9/20 Train Loss: 0.0469 Val Loss: 1.2672\n",
      "[efficientnet] Epoch 10/20 Train Loss: 0.0375 Val Loss: 1.3308\n",
      "[efficientnet] Epoch 11/20 Train Loss: 0.0406 Val Loss: 1.2962\n",
      "[efficientnet] Epoch 12/20 Train Loss: 0.0344 Val Loss: 1.1500\n",
      "[efficientnet] Epoch 13/20 Train Loss: 0.0254 Val Loss: 1.1484\n",
      "[efficientnet] Epoch 14/20 Train Loss: 0.0210 Val Loss: 1.1057\n",
      "[efficientnet] Epoch 15/20 Train Loss: 0.0224 Val Loss: 1.1316\n",
      "[efficientnet] Epoch 16/20 Train Loss: 0.0148 Val Loss: 1.2640\n",
      "[efficientnet] Epoch 17/20 Train Loss: 0.0181 Val Loss: 1.3818\n",
      "[efficientnet] Epoch 18/20 Train Loss: 0.0210 Val Loss: 1.4357\n",
      "[efficientnet] Epoch 19/20 Train Loss: 0.0281 Val Loss: 1.3419\n",
      "[efficientnet] Epoch 20/20 Train Loss: 0.0315 Val Loss: 1.2287\n",
      "Kaggle submission saved to: submission\\submission_efficientnet_task1_3.csv\n",
      "\n",
      "OFFSITE test results for efficientnet - full_ft\n",
      "Average F1 over 3 diseases (offsite): 0.6958\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backbone</th>\n",
       "      <th>Task</th>\n",
       "      <th>Split</th>\n",
       "      <th>Disease</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>efficientnet</td>\n",
       "      <td>full_ft</td>\n",
       "      <td>offsite</td>\n",
       "      <td>DR</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.879032</td>\n",
       "      <td>0.778571</td>\n",
       "      <td>0.825758</td>\n",
       "      <td>0.491150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>efficientnet</td>\n",
       "      <td>full_ft</td>\n",
       "      <td>offsite</td>\n",
       "      <td>Glaucoma</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.752475</td>\n",
       "      <td>0.668962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>efficientnet</td>\n",
       "      <td>full_ft</td>\n",
       "      <td>offsite</td>\n",
       "      <td>AMD</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.434437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>efficientnet</td>\n",
       "      <td>full_ft</td>\n",
       "      <td>offsite</td>\n",
       "      <td>Average F1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.695775</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Backbone     Task    Split     Disease  Accuracy  Precision    Recall  \\\n",
       "0  efficientnet  full_ft  offsite          DR     0.770   0.879032  0.778571   \n",
       "1  efficientnet  full_ft  offsite    Glaucoma     0.875   0.730769  0.775510   \n",
       "2  efficientnet  full_ft  offsite         AMD     0.865   0.424242  0.636364   \n",
       "3  efficientnet  full_ft  offsite  Average F1       NaN        NaN       NaN   \n",
       "\n",
       "   F1-score     Kappa  \n",
       "0  0.825758  0.491150  \n",
       "1  0.752475  0.668962  \n",
       "2  0.509091  0.434437  \n",
       "3  0.695775       NaN  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 1.3 full fine-tune, efficientnet\n",
    "\n",
    "backbone = \"efficientnet\" \n",
    "\n",
    "if backbone == \"resnet18\":\n",
    "    pretrained_path = pretrained_resnet18\n",
    "elif backbone == \"efficientnet\":\n",
    "    pretrained_path = pretrained_efficient\n",
    "else:\n",
    "    raise ValueError(\"unknown backbone\")\n",
    "\n",
    "#offsite\n",
    "ckpt_task13, y_true_offsite, y_pred_offsite = train_one_backbone(\n",
    "    backbone=backbone,\n",
    "    train_csv=train_csv,\n",
    "    val_csv=val_csv,\n",
    "    test_csv=offsite_test_csv,\n",
    "    train_image_dir=train_img_dir,\n",
    "    val_image_dir=val_img_dir,\n",
    "    test_image_dir=offsite_img_dir,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    lr=4e-4,\n",
    "    img_size=img_size,\n",
    "    save_dir=save_dir,\n",
    "    pretrained_backbone=pretrained_path,\n",
    "    task=\"full_ft\",\n",
    ")\n",
    "\n",
    "\n",
    "#onsite\n",
    "generate_kaggle_submission(\n",
    "    backbone=backbone,\n",
    "    ckpt_path=ckpt_task13,\n",
    "    onsite_csv=onsite_csv,          \n",
    "    onsite_image_dir=onsite_img_dir,\n",
    "    img_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    out_csv=f\"submission_{backbone}_task1_3.csv\",\n",
    ")\n",
    "\n",
    "df_offsite = evaluating_metrics(\n",
    "    y_true=y_true_offsite,\n",
    "    y_pred=y_pred_offsite,\n",
    "    backbone=backbone,\n",
    "    task_name=\"full_ft\",\n",
    "    split_name=\"offsite\",\n",
    ")\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "df_offsite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0594be2c-e631-45e8-9ec2-da3a9f571a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bbcad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f97f7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0021d693",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
