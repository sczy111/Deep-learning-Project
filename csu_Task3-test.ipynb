{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffd5c52e-3739-436b-a7a6-3ffb7d9dc634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score\n",
    "import torch.nn.functional as F\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35b9b0b2-21a3-42d7-907d-04f847bd8341",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e12745-9728-49ea-9231-55c95da3d12b",
   "metadata": {},
   "source": [
    "## Task 3. Attention Mechanisms\n",
    "\n",
    "The following sections include utility functions and two modular attention components:\n",
    "\n",
    "- **Task 3.1 — Squeeze-and-Excitation (SE):**  \n",
    "  A lightweight channel-wise attention module that adaptively recalibrates feature maps via global pooling and two fully-connected layers.\n",
    "\n",
    "- **Task 3.2 — Multi-Head Attention (MHA):**  \n",
    "  A transformer-style attention block that splits feature channels into multiple heads to capture diverse relationships.\n",
    "\n",
    "Both mechanisms are implemented as standalone PyTorch modules and can be attached to the backbone model before training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af951e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Dataset preparation\n",
    "# ========================\n",
    "class RetinaMultiLabelDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        img_path = os.path.join(self.image_dir, row.iloc[0])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        labels = torch.tensor(row[1:].values.astype(\"float32\"))\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, labels\n",
    "\n",
    "class RetinaTestDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_dir, transform=None):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        self.ids = df.iloc[:, 0].values  # first column -> id/ID\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.ids[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_id)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, img_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79bf3dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# build model\n",
    "# ========================\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "\n",
    "def build_model(backbone=\"resnet18\", num_classes=3, pretrained=True):\n",
    "    if backbone == \"resnet18\":\n",
    "        weights = ResNet18_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "        model = resnet18(weights=weights)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "    elif backbone == \"efficientnet\":\n",
    "        weights = EfficientNet_B0_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "        model = efficientnet_b0(weights=weights)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported backbone\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bd270fd-ca6f-4461-b69b-816c471c8408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FocalLoss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction=\"mean\"):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "        if alpha is not None:\n",
    "            alpha = torch.tensor(alpha, dtype=torch.float32)\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        \"\"\"\n",
    "        logits: [B, C] raw model outputs\n",
    "        targets: [B, C] in {0,1}\n",
    "        \"\"\"\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(\n",
    "            logits, targets, reduction=\"none\"\n",
    "        )\n",
    "        probs = torch.sigmoid(logits)\n",
    "        p_t = probs * targets + (1 - probs) * (1 - targets)\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            alpha = self.alpha.to(logits.device)\n",
    "            # broadcast alpha if it's per-class\n",
    "            if alpha.dim() == 1:\n",
    "                alpha = alpha.view(1, -1)  # [1, C]\n",
    "            alpha_t = alpha * targets + (1 - alpha) * (1 - targets)\n",
    "        else:\n",
    "            alpha_t = 1.0\n",
    "\n",
    "        # focal modulation\n",
    "        focal_factor = (1.0 - p_t) ** self.gamma\n",
    "        loss = alpha_t * focal_factor * bce_loss  # [B, C]\n",
    "\n",
    "        if self.reduction == \"mean\":\n",
    "            return loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss  # [B, C]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad0cf289-7202-4bc3-9701-e2578605711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ClassBalancedBCELoss\n",
    "def compute_class_frequency_weights_from_csv(train_csv_path, num_classes=3):\n",
    "    df = pd.read_csv(train_csv_path)\n",
    "    label_cols = df.columns[1 : 1 + num_classes]  # skip ID\n",
    "    pos_counts = df[label_cols].sum(axis=0).values.astype(np.float32)\n",
    "    total = len(df)\n",
    "\n",
    "    # positive frequency per class\n",
    "    freq = pos_counts / (total + 1e-6)\n",
    "\n",
    "    # inverse frequency as weights\n",
    "    inv_freq = 1.0 / (freq + 1e-6)\n",
    "    inv_freq = inv_freq / inv_freq.mean()\n",
    "\n",
    "    return torch.tensor(inv_freq, dtype=torch.float32)\n",
    "class ClassBalancedBCELoss(nn.Module):\n",
    "    def __init__(self, class_weights, reduction=\"mean\"):\n",
    "        super(ClassBalancedBCELoss, self).__init__()\n",
    "        self.class_weights = class_weights  \n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        \"\"\"\n",
    "        logits: [B, C]\n",
    "        targets: [B, C]\n",
    "        \"\"\"\n",
    "        bce = F.binary_cross_entropy_with_logits(\n",
    "            logits, targets, reduction=\"none\"\n",
    "        )\n",
    "\n",
    "        w = self.class_weights.to(logits.device).view(1, -1)\n",
    "        loss = bce * w\n",
    "\n",
    "        if self.reduction == \"mean\":\n",
    "            return loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "491c7527-9a51-49a9-9501-1b7bf7ff94df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squeeze-and-Excitation\n",
    "class SEBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Squeeze-and-Excitation for 2D feature maps: (B, C, H, W) -> (B, C, H, W)\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)      # (B, C)\n",
    "        y = self.fc(y).view(b, c, 1, 1)      # (B, C, 1, 1)\n",
    "        return x * y                         # channel-wise rescale\n",
    "        \n",
    "# Multi-Head Attention\n",
    "class MHABlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-head self-attention on a sequence of tokens of dim embed_dim.\n",
    "    Input: x of shape (B, N, C)  (N = number of spatial locations)\n",
    "    Output: same shape.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.mha = nn.MultiheadAttention(\n",
    "            embed_dim=embed_dim,\n",
    "            num_heads=num_heads,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, N, C)\n",
    "        attn_out, _ = self.mha(x, x, x)  # self-attention\n",
    "        x = x + attn_out                 # residual\n",
    "        x = self.norm(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89102c04-7564-40b4-8de2-45c19bb42c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap model and insert attention to it\n",
    "class ResNetWithAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Wraps a ResNet18-like model and inserts SE or MHA after layer4.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_model, attention=\"se\", num_heads=4):\n",
    "        super().__init__()\n",
    "        self.attention = attention\n",
    "\n",
    "        # Copy ResNet structure\n",
    "        self.conv1   = base_model.conv1\n",
    "        self.bn1     = base_model.bn1\n",
    "        self.relu    = base_model.relu\n",
    "        self.maxpool = base_model.maxpool\n",
    "        self.layer1  = base_model.layer1\n",
    "        self.layer2  = base_model.layer2\n",
    "        self.layer3  = base_model.layer3\n",
    "        self.layer4  = base_model.layer4\n",
    "        self.avgpool = base_model.avgpool\n",
    "        self.fc      = base_model.fc\n",
    "\n",
    "        # Number of channels after layer4\n",
    "        channels = self.layer4[-1].conv2.out_channels\n",
    "\n",
    "        if attention == \"se\":\n",
    "            self.attn = SEBlock(channels)\n",
    "        elif attention == \"mha\":\n",
    "            self.attn = MHABlock(embed_dim=channels, num_heads=num_heads)\n",
    "        else:\n",
    "            self.attn = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)    # (B, C, H, W)\n",
    "\n",
    "        if self.attn is not None:\n",
    "            if self.attention == \"se\":\n",
    "                x = self.attn(x)\n",
    "            else:  # MHA over spatial tokens\n",
    "                b, c, h, w = x.shape\n",
    "                x_flat = x.view(b, c, h * w).permute(0, 2, 1)\n",
    "                x_flat = self.attn(x_flat)\n",
    "                x = x_flat.permute(0, 2, 1).view(b, c, h, w)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EfficientNetWithAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Wraps an EfficientNet-like model and inserts SE or MHA after features.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_model, attention=\"se\", num_heads=4):\n",
    "        super().__init__()\n",
    "        self.attention = attention\n",
    "\n",
    "        self.features = base_model.features\n",
    "        # Some efficientnets have .avgpool, else use AdaptiveAvgPool2d(1)\n",
    "        self.avgpool = getattr(base_model, \"avgpool\", nn.AdaptiveAvgPool2d(1))\n",
    "        self.classifier = base_model.classifier\n",
    "\n",
    "        # Get channel dim from classifier input\n",
    "        if isinstance(self.classifier, nn.Sequential):\n",
    "            for m in self.classifier.modules():\n",
    "                if isinstance(m, nn.Linear):\n",
    "                    in_features = m.in_features\n",
    "                    break\n",
    "        else:\n",
    "            in_features = self.classifier.in_features\n",
    "\n",
    "        channels = in_features  # after global pooling\n",
    "\n",
    "        if attention == \"se\":\n",
    "            self.attn = SEBlock(channels)\n",
    "        elif attention == \"mha\":\n",
    "            self.attn = MHABlock(embed_dim=channels, num_heads=num_heads)\n",
    "        else:\n",
    "            self.attn = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)              # (B, C, H, W)\n",
    "\n",
    "        # For SE/MHA we want to operate on spatial feature map\n",
    "        if self.attn is not None:\n",
    "            if self.attention == \"se\":\n",
    "                # Apply SE in 2D form\n",
    "                x = self.attn(x)\n",
    "            else:\n",
    "                # MHA over spatial tokens\n",
    "                b, c, h, w = x.shape\n",
    "                x_flat = x.view(b, c, h * w).permute(0, 2, 1)\n",
    "                x_flat = self.attn(x_flat)\n",
    "                x = x_flat.permute(0, 2, 1).view(b, c, h, w)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e67787b-0465-4614-a926-e9683972bd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small helper to attach attention to a backbone\n",
    "def add_attention(model, backbone, attention=\"none\", num_heads=4):\n",
    "    if attention is None or attention == \"none\":\n",
    "        return model\n",
    "\n",
    "    if backbone == \"resnet18\":\n",
    "        return ResNetWithAttention(model, attention=attention, num_heads=num_heads)\n",
    "    elif backbone == \"efficientnet\":\n",
    "        return EfficientNetWithAttention(model, attention=attention, num_heads=num_heads)\n",
    "    else:\n",
    "        raise ValueError(f\"Attention wrapper not implemented for backbone: {backbone}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "747e2295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# model training and val\n",
    "# ========================\n",
    "def train_one_backbone(\n",
    "    backbone,\n",
    "    train_csv,\n",
    "    val_csv,\n",
    "    test_csv,\n",
    "    train_image_dir,\n",
    "    val_image_dir,\n",
    "    test_image_dir,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    lr=1e-4,\n",
    "    img_size=256,\n",
    "    save_dir=\"checkpoints\",\n",
    "    pretrained_backbone=None,\n",
    "    task=\"full_ft\",\n",
    "    loss=\"bce\",  # \"bce\", \"focal\", \"cb\"\n",
    "    alpha=None,\n",
    "    gamma=2.0,\n",
    "    attention=\"none\",  # \"none\", \"se\", \"mha\"\n",
    "    num_heads=4,       # number of heads for MHA\n",
    "):\n",
    "\n",
    "    device = torch.device(torch.cuda.is_available() and \"cuda\" or \"cpu\")\n",
    "    print(device)\n",
    "\n",
    "    task_name_map = {\n",
    "        \"no_finetune\": \"Task1.1 No fine-tuning\",\n",
    "        \"cls_only\": \"Task1.2 Frozen backbone, classifier only\",\n",
    "        \"full_ft\": \"Task1.3 Full fine-tuning\",\n",
    "    }\n",
    "\n",
    "    print(\"===========================================\")\n",
    "    print(f\"Task 3 |  Backbone: {backbone} | loss: {loss} | attention: {attention}\")\n",
    "    print(\"===========================================\")\n",
    "\n",
    "    # transforms\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # datasets & dataloaders\n",
    "    train_ds = RetinaMultiLabelDataset(train_csv, train_image_dir, transform)\n",
    "    val_ds   = RetinaMultiLabelDataset(val_csv,   val_image_dir,   transform)\n",
    "    test_ds  = RetinaMultiLabelDataset(test_csv,  test_image_dir,  transform)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=0)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    # model\n",
    "    model = build_model(backbone, num_classes=3, pretrained=False)\n",
    "\n",
    "    # plug in attention\n",
    "    model = add_attention(model, backbone=backbone, attention=attention, num_heads=num_heads)\n",
    "    model = model.to(device)\n",
    "\n",
    "    if pretrained_backbone is not None:\n",
    "        state_dict = torch.load(pretrained_backbone, map_location=\"cpu\")\n",
    "        has_attn = any(k.startswith(\"attn.\") for k in state_dict.keys())\n",
    "    \n",
    "        if has_attn:\n",
    "            # checkpoint already from attention model\n",
    "            model.load_state_dict(state_dict, strict=False)\n",
    "            print(f\"Loaded attention checkpoint from {pretrained_backbone}\")\n",
    "        else:\n",
    "            # checkpoint from plain backbone (Task 1/2)\n",
    "            model.load_state_dict(state_dict, strict=False)\n",
    "            print(f\"Loaded non-attention backbone checkpoint from {pretrained_backbone}\")\n",
    "\n",
    "\n",
    "    # set which parameters are trainable\n",
    "    if task == \"no_finetune\":\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = False\n",
    "        optimizer = None\n",
    "\n",
    "    elif task == \"cls_only\":\n",
    "        # freeze everything\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        # unfreeze classifier only (attention stays frozen in this task)\n",
    "        if backbone == \"resnet18\":\n",
    "            for p in model.fc.parameters():\n",
    "                p.requires_grad = True\n",
    "        elif backbone == \"efficientnet\":\n",
    "            for p in model.classifier.parameters():\n",
    "                p.requires_grad = True\n",
    "\n",
    "        optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "\n",
    "    else:  # full_ft\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = True\n",
    "        optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "        # scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "    # ----- choose loss function -----\n",
    "    if loss == \"bce\":\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "    elif loss == \"focal\":\n",
    "        criterion = FocalLoss(alpha=alpha, gamma=gamma, reduction=\"mean\")\n",
    "    elif loss == \"cb\":\n",
    "        class_weights = compute_class_frequency_weights_from_csv(train_csv, num_classes=3)\n",
    "        criterion = ClassBalancedBCELoss(class_weights=class_weights, reduction=\"mean\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown loss_type: {loss}\")\n",
    "\n",
    "    # checkpoint path (unique per backbone + task)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    attention_name_map = {\n",
    "        \"none\": \"task3.0 No Attention\",\n",
    "        \"se\":   \"task3_1\",\n",
    "        \"mha\":  \"task3_2\",\n",
    "    }\n",
    "\n",
    "    task_prefix = attention_name_map[attention]\n",
    "    ckpt_path = os.path.join(save_dir, f\"csu_{task_prefix}_{backbone}_{attention}.pt\")\n",
    "\n",
    "    # ========= TRAINING  =========\n",
    "    if task != \"no_finetune\":\n",
    "        best_val_loss = float(\"inf\")\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            for imgs, labels in train_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(imgs)\n",
    "                loss_value = criterion(outputs, labels)\n",
    "                loss_value.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss_value.item() * imgs.size(0)\n",
    "\n",
    "            train_loss /= len(train_loader.dataset)\n",
    "\n",
    "            # validation\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_probs_all = []\n",
    "            val_labels_all = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for imgs, labels in val_loader:\n",
    "                    imgs, labels = imgs.to(device), labels.to(device)\n",
    "                    outputs = model(imgs)\n",
    "                    loss_value = criterion(outputs, labels)\n",
    "                    val_loss += loss_value.item() * imgs.size(0)\n",
    "                    probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "                    val_probs_all.extend(probs)\n",
    "                    val_labels_all.extend(labels.cpu().numpy())\n",
    "\n",
    "            val_loss /= len(val_loader.dataset)\n",
    "            val_probs_all = np.array(val_probs_all)\n",
    "            val_labels_all = np.array(val_labels_all)\n",
    "\n",
    "            print(f\"[{backbone} | {attention}] Epoch {epoch+1}/{epochs} \"\n",
    "                  f\"Train Loss: {train_loss:.4f} Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "            # save best\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                torch.save(model.state_dict(), ckpt_path)\n",
    "                print(f\"Saved best model for {backbone} ({task}, {attention}) at {ckpt_path}\")\n",
    "    else:\n",
    "        torch.save(model.state_dict(), ckpt_path)\n",
    "        print(f\"[{backbone}] {task_name_map[task]}: no training, model saved at {ckpt_path}\")\n",
    "\n",
    "    # ========= OFFSITE TEST EVALUATION =========\n",
    "    model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in test_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            outputs = model(imgs)\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "            preds = (probs > 0.5).astype(int)\n",
    "            y_true.extend(labels.numpy())\n",
    "            y_pred.extend(preds)\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    return ckpt_path, y_true, y_pred, val_probs_all, val_labels_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0086b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_kaggle_submission(\n",
    "    backbone,\n",
    "    ckpt_path,\n",
    "    onsite_csv,\n",
    "    onsite_image_dir,\n",
    "    img_size=256,\n",
    "    batch_size=32,\n",
    "    out_csv=\"submission.csv\",\n",
    "    threshold=0.5,\n",
    "    best=False,\n",
    "    attention=\"none\",   #  \"none\", \"se\", \"mha\"\n",
    "    num_heads=4,        #  for MHA\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # --- build model and load weights (MATCH training arch) ---\n",
    "    model = build_model(backbone, num_classes=3, pretrained=False)\n",
    "    model = add_attention(model, backbone=backbone, attention=attention, num_heads=num_heads)\n",
    "    model = model.to(device)\n",
    "\n",
    "    state_dict = torch.load(ckpt_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)  # strict=True is fine here\n",
    "    model.eval()\n",
    "\n",
    "    # read the original Kaggle template\n",
    "    template = pd.read_csv(onsite_csv)\n",
    "    id_col_name = template.columns[0] \n",
    "\n",
    "    # dataset and loader use the same csv for IDs\n",
    "    test_ds = RetinaTestDataset(onsite_csv, onsite_image_dir, transform)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    ids = []\n",
    "    probs_all = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, img_ids in test_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            outputs = model(imgs)\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "            ids.extend(img_ids)\n",
    "            probs_all.append(probs)\n",
    "\n",
    "    probs_all = np.concatenate(probs_all, axis=0)\n",
    "\n",
    "    template_ids = template[id_col_name].values\n",
    "    ids = np.array(ids)\n",
    "\n",
    "    if not np.array_equal(template_ids, ids):\n",
    "        print(\"WARNING: IDs in template and predictions do not match exactly in order!\")\n",
    "        id_to_idx = {image_id: i for i, image_id in enumerate(ids)}\n",
    "        reorder_idx = [id_to_idx[x] for x in template_ids]\n",
    "        probs_all = probs_all[reorder_idx, :]\n",
    "\n",
    "    # convert probabilities to 0/1 labels using threshold\n",
    "    if best:\n",
    "        thr = np.array(threshold, dtype=float)\n",
    "        if thr.ndim == 0:  # scalar threshold\n",
    "            bin_preds = (probs_all >= thr).astype(int)\n",
    "        else:              # per-class thresholds\n",
    "            bin_preds = (probs_all >= thr.reshape(1, -1)).astype(int)\n",
    "    else:\n",
    "        bin_preds = (probs_all >= threshold).astype(int)\n",
    "\n",
    "    template[\"D\"] = bin_preds[:, 0]\n",
    "    template[\"G\"] = bin_preds[:, 1]\n",
    "    template[\"A\"] = bin_preds[:, 2]\n",
    "\n",
    "    out_dir = \"submission\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out_path = os.path.join(out_dir, out_csv)\n",
    "    tmp_path = out_path + \".tmp\"\n",
    "    template.to_csv(tmp_path, index=False)\n",
    "    os.replace(tmp_path, out_path)\n",
    "\n",
    "    print(f\"Kaggle submission saved to: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb90d0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluating_metrics(y_true, y_pred, backbone, task_name,split_name):\n",
    "    \n",
    "    disease_names = [\"DR\", \"Glaucoma\", \"AMD\"]\n",
    "    rows = []\n",
    "    f1_list = []\n",
    "\n",
    "    print(f\"\\n{split_name.upper()} test results for {backbone} - {task_name}\")\n",
    "\n",
    "    for i, disease in enumerate(disease_names):\n",
    "        yt = y_true[:, i]\n",
    "        yp = y_pred[:, i]\n",
    "\n",
    "        acc = accuracy_score(yt, yp)\n",
    "        precision = precision_score(yt, yp, zero_division=0)\n",
    "        recall = recall_score(yt, yp, zero_division=0)\n",
    "        f1 = f1_score(yt, yp, zero_division=0)\n",
    "        kappa = cohen_kappa_score(yt, yp)\n",
    "\n",
    "        f1_list.append(f1)\n",
    "\n",
    "        \"\"\"# print in the required format (optional)\n",
    "        print(f\"{disease} Results [{backbone}] ({split_name})\")\n",
    "        print(f\"Accuracy : {acc:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall   : {recall:.4f}\")\n",
    "        print(f\"F1-score : {f1:.4f}\")\n",
    "        print(f\"Kappa    : {kappa:.4f}\")\n",
    "        print(\"-----\")\"\"\"\n",
    "\n",
    "        rows.append({\n",
    "            \"Backbone\": backbone,\n",
    "            \"Task\": task_name,\n",
    "            \"Split\": split_name,\n",
    "            \"Disease\": disease,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"F1-score\": f1,\n",
    "            \"Kappa\": kappa,\n",
    "        })\n",
    "\n",
    "    avg_f1 = sum(f1_list) / len(f1_list)\n",
    "    print(f\"Average F1 over 3 diseases ({split_name}): {avg_f1:.4f}\\n\")\n",
    "\n",
    "    rows.append({\n",
    "        \"Backbone\": backbone,\n",
    "        \"Task\": task_name,\n",
    "        \"Split\": split_name,\n",
    "        \"Disease\": \"Average F1\",\n",
    "        \"Accuracy\": None,\n",
    "        \"Precision\": None,\n",
    "        \"Recall\": None,\n",
    "        \"F1-score\": avg_f1,\n",
    "        \"Kappa\": None,\n",
    "    })\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0851faf-48ba-4903-845c-3db06a427b21",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "This section defines all dataset paths, pretrained backbone locations, and key training hyperparameters. Adjust these values to match your local setup before running the experiments. The class frequency–based alpha vector is also computed here for optional use in loss functions. In the version I ran, this vector was not used, but you may enable it if you wish to experiment with it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "790a056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration (edit paths here)\n",
    "\n",
    "\n",
    "# Labeled splits\n",
    "train_csv = \"train.csv\"\n",
    "val_csv = \"val.csv\"\n",
    "offsite_test_csv = \"offsite_test.csv\"\n",
    "\n",
    "train_img_dir = \"./images/train\"\n",
    "val_img_dir = \"./images/val\"\n",
    "offsite_img_dir = \"./images/offsite_test\"\n",
    "\n",
    "# unlabeled onsite test (for kaggle submission)\n",
    "onsite_csv = \"onsite_test_submission.csv\"\n",
    "onsite_img_dir = \"./images/onsite_test\"\n",
    "\n",
    "# optional: your own pretrained backbones\n",
    "pretrained_resnet18 = \"./pretrained_backbone/ckpt_resnet18_ep50.pt\"\n",
    "pretrained_efficient = \"./pretrained_backbone/ckpt_efficientnet_ep50.pt\"\n",
    "\n",
    "img_size = 256\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "lr = 1e-4\n",
    "save_dir = \"checkpoints\"\n",
    "\n",
    "# per-class alpha based on disease frequency\n",
    "df = pd.read_csv(train_csv)\n",
    "label_cols = df.columns[1:4]  \n",
    "pos_counts = df[label_cols].sum(axis=0).values.astype(np.float32)\n",
    "total = len(df)\n",
    "freq = pos_counts / (total + 1e-6)\n",
    "alpha_vec = 1.0 - freq\n",
    "alpha_vec = alpha_vec / alpha_vec.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac37ae84-d490-4582-926b-6cd6814ff5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_thresholds(probs_val, y_val, disease_names=(\"DR\",\"Glaucoma\",\"AMD\")):\n",
    "    best_thrs = []\n",
    "    for i, name in enumerate(disease_names):\n",
    "        best_f1 = -1\n",
    "        best_t = 0.5\n",
    "        for t in np.linspace(0.1, 0.9, 81):\n",
    "            preds = (probs_val[:, i] > t).astype(int)\n",
    "            f1 = f1_score(y_val[:, i], preds, zero_division=0)\n",
    "            if f1 > best_f1:\n",
    "                best_f1, best_t = f1, t\n",
    "        print(f\"{name}: best thr={best_t:.2f}, val F1={best_f1:.4f}\")\n",
    "        best_thrs.append(best_t)\n",
    "    return np.array(best_thrs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad02139b-1d31-40ac-9afc-976549ba09be",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "This section includes all training runs used to generate the results presented in the report and submitted to Kaggle. The preliminary results and metrics shown here were used directly in the report, and the hyperparameters in the code match the exact configurations of the final experiments. Because training is stochastic, your results may not match mine exactly, but repeated runs should produce similar outcomes.\n",
    "\n",
    "\n",
    "Each task is organized into its own code block. For example:\n",
    "\n",
    "- `# Task 3.1 resnet18`  \n",
    "\n",
    "A separate block in each subtask includes the large-scale hyperparameter search used to identify the best-performing settings. These experiments are commented out because they require substantial compute time, but the preliminary results are shown for reference.\n",
    "\n",
    "After running multiple trials, the best-performing configuration was selected for the final model and Kaggle submission. Your single run may not match the final score exactly, but repeated runs should produce similar performance. Though the number of repeated runs maybe large. And you need to have enough VRAM as some of the configurations were using batch_size = 128.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed573603-a158-4c7c-a934-9c21d33b04c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import gc\\n\\nbackbone = \"resnet18\"\\ncheckpoint = \"./checkpoints/task1/csu_task1_2_resnet18.pt\"  # starting checkpoint for full_ft\\n\\nif backbone == \"resnet18\":\\n    pretrained_path = pretrained_resnet18\\nelif backbone == \"efficientnet\":\\n    pretrained_path = pretrained_efficient\\nelse:\\n    raise ValueError(\"unknown backbone\")\\n\\n# -------------------------\\n# Hyperparameter grids\\n# -------------------------\\nlrs = [\\n    1e-3, 9e-4, 8e-4, 7e-4, 6e-4, 5e-4, 4e-4, 3e-4, 2e-4, 1e-4,\\n    9e-5, 8e-5, 7e-5, 6e-5, 5e-5, 4e-5, 3e-5, 2e-5, 1e-5\\n]\\nbatch_sizes = [64,32]\\n\\nresults = []  # will store dicts with ckpt_path, avg_f1, and hyperparams\\n\\nexp_id = 0\\n\\nfor lr in lrs:\\n    for batch_size in batch_sizes:\\n        exp_id += 1\\n        print(\"=\" * 60)\\n        print(f\"Experiment {exp_id}: lr={lr}, batch_size={batch_size}\")\\n        print(\"=\" * 60)\\n\\n        # ---- Train with given hyperparameters ----\\n        ckpt_path, y_true_offsite, y_pred_offsite, val_probs, val_labels = train_one_backbone(\\n            backbone=backbone,\\n            train_csv=train_csv,\\n            val_csv=val_csv,\\n            test_csv=offsite_test_csv,\\n            train_image_dir=train_img_dir,\\n            val_image_dir=val_img_dir,\\n            test_image_dir=offsite_img_dir,\\n            epochs=12,\\n            batch_size=batch_size,\\n            lr=lr,\\n            img_size=img_size,\\n            save_dir=save_dir,\\n            pretrained_backbone=checkpoint,  # or pretrained_path if you prefer\\n            task=\"full_ft\",\\n            attention=\"se\",\\n        )\\n\\n        # ---- Compute validation-based thresholds (for later use on onsite) ----\\n        best_thrs = find_best_thresholds(val_probs, val_labels)\\n\\n        # ---- Compute OFFSITE metrics (used to rank models) ----\\n        df_off = evaluating_metrics(\\n            y_true=y_true_offsite,\\n            y_pred=y_pred_offsite,\\n            backbone=backbone,\\n            task_name=f\"full_ft_cb_lr{lr}_bs{batch_size}\",\\n            split_name=\"offsite\",\\n        )\\n\\n        # Extract average F1 row (assuming your df has \\'Disease\\' == \\'Average F1\\')\\n        try:\\n            avg_f1 = df_off.loc[df_off[\"Disease\"] == \"Average F1\", \"F1-score\"].values[0]\\n        except Exception as e:\\n            print(\"WARNING: Could not extract average F1 from df_off, defaulting to 0.0\")\\n            print(\"Error:\", e)\\n            avg_f1 = 0.0\\n\\n        print(f\"OFFSITE Average F1 for this config: {avg_f1:.4f}\")\\n\\n        # ---- Store result ----\\n        results.append(\\n            {\\n                \"ckpt_path\": ckpt_path,\\n                \"avg_f1\": float(avg_f1),\\n                \"lr\": lr,\\n                \"batch_size\": batch_size,\\n                \"best_thrs\": best_thrs,\\n            }\\n        )\\n\\n        # ---- Clean up GPU memory ----\\n        del y_true_offsite, y_pred_offsite, val_probs, val_labels\\n        gc.collect()\\n        torch.cuda.empty_cache()\\n\\n# -------------------------\\n# Select top 3 configurations\\n# -------------------------\\nresults_sorted = sorted(results, key=lambda x: x[\"avg_f1\"], reverse=True)\\ntop3 = results_sorted[:3]\\n\\nprint(\"\\n\" + \"#\" * 60)\\nprint(\"TOP 3 CONFIGURATIONS (by OFFSITE average F1)\")\\nprint(\"#\" * 60)\\n\\nfor rank, r in enumerate(top3, start=1):\\n    print(\\n        f\"Rank {rank}: avg_F1={r[\\'avg_f1\\']:.4f}, \"\\n        f\"lr={r[\\'lr\\']}, batch_size={r[\\'batch_size\\']}, \"\\n        f\"ckpt={r[\\'ckpt_path\\']}\"\\n    )\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# task 3.1 resnet18,  Squeeze-and-Excitation, try different hyperparameters to find the best ones\n",
    "# No need to run this unless you are interested, though the pre result are preserved here.\n",
    "\"\"\"import gc\n",
    "\n",
    "backbone = \"resnet18\"\n",
    "checkpoint = \"./checkpoints/task1/csu_task1_2_resnet18.pt\"  # starting checkpoint for full_ft\n",
    "\n",
    "if backbone == \"resnet18\":\n",
    "    pretrained_path = pretrained_resnet18\n",
    "elif backbone == \"efficientnet\":\n",
    "    pretrained_path = pretrained_efficient\n",
    "else:\n",
    "    raise ValueError(\"unknown backbone\")\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter grids\n",
    "# -------------------------\n",
    "lrs = [\n",
    "    1e-3, 9e-4, 8e-4, 7e-4, 6e-4, 5e-4, 4e-4, 3e-4, 2e-4, 1e-4,\n",
    "    9e-5, 8e-5, 7e-5, 6e-5, 5e-5, 4e-5, 3e-5, 2e-5, 1e-5\n",
    "]\n",
    "batch_sizes = [64,32]\n",
    "\n",
    "results = []  # will store dicts with ckpt_path, avg_f1, and hyperparams\n",
    "\n",
    "exp_id = 0\n",
    "\n",
    "for lr in lrs:\n",
    "    for batch_size in batch_sizes:\n",
    "        exp_id += 1\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Experiment {exp_id}: lr={lr}, batch_size={batch_size}\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        # ---- Train with given hyperparameters ----\n",
    "        ckpt_path, y_true_offsite, y_pred_offsite, val_probs, val_labels = train_one_backbone(\n",
    "            backbone=backbone,\n",
    "            train_csv=train_csv,\n",
    "            val_csv=val_csv,\n",
    "            test_csv=offsite_test_csv,\n",
    "            train_image_dir=train_img_dir,\n",
    "            val_image_dir=val_img_dir,\n",
    "            test_image_dir=offsite_img_dir,\n",
    "            epochs=12,\n",
    "            batch_size=batch_size,\n",
    "            lr=lr,\n",
    "            img_size=img_size,\n",
    "            save_dir=save_dir,\n",
    "            pretrained_backbone=checkpoint,  # or pretrained_path if you prefer\n",
    "            task=\"full_ft\",\n",
    "            attention=\"se\",\n",
    "        )\n",
    "\n",
    "        # ---- Compute validation-based thresholds (for later use on onsite) ----\n",
    "        best_thrs = find_best_thresholds(val_probs, val_labels)\n",
    "\n",
    "        # ---- Compute OFFSITE metrics (used to rank models) ----\n",
    "        df_off = evaluating_metrics(\n",
    "            y_true=y_true_offsite,\n",
    "            y_pred=y_pred_offsite,\n",
    "            backbone=backbone,\n",
    "            task_name=f\"full_ft_cb_lr{lr}_bs{batch_size}\",\n",
    "            split_name=\"offsite\",\n",
    "        )\n",
    "\n",
    "        # Extract average F1 row (assuming your df has 'Disease' == 'Average F1')\n",
    "        try:\n",
    "            avg_f1 = df_off.loc[df_off[\"Disease\"] == \"Average F1\", \"F1-score\"].values[0]\n",
    "        except Exception as e:\n",
    "            print(\"WARNING: Could not extract average F1 from df_off, defaulting to 0.0\")\n",
    "            print(\"Error:\", e)\n",
    "            avg_f1 = 0.0\n",
    "\n",
    "        print(f\"OFFSITE Average F1 for this config: {avg_f1:.4f}\")\n",
    "\n",
    "        # ---- Store result ----\n",
    "        results.append(\n",
    "            {\n",
    "                \"ckpt_path\": ckpt_path,\n",
    "                \"avg_f1\": float(avg_f1),\n",
    "                \"lr\": lr,\n",
    "                \"batch_size\": batch_size,\n",
    "                \"best_thrs\": best_thrs,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # ---- Clean up GPU memory ----\n",
    "        del y_true_offsite, y_pred_offsite, val_probs, val_labels\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# -------------------------\n",
    "# Select top 3 configurations\n",
    "# -------------------------\n",
    "results_sorted = sorted(results, key=lambda x: x[\"avg_f1\"], reverse=True)\n",
    "top3 = results_sorted[:3]\n",
    "\n",
    "print(\"\\n\" + \"#\" * 60)\n",
    "print(\"TOP 3 CONFIGURATIONS (by OFFSITE average F1)\")\n",
    "print(\"#\" * 60)\n",
    "\n",
    "for rank, r in enumerate(top3, start=1):\n",
    "    print(\n",
    "        f\"Rank {rank}: avg_F1={r['avg_f1']:.4f}, \"\n",
    "        f\"lr={r['lr']}, batch_size={r['batch_size']}, \"\n",
    "        f\"ckpt={r['ckpt_path']}\"\n",
    "    )\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d207cb5b-5886-4294-9f9f-07d2b00e3825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "===========================================\n",
      "Task 3 |  Backbone: resnet18 | loss: cb | attention: se\n",
      "===========================================\n",
      "Loaded non-attention backbone checkpoint from ./checkpoints/task2/csu_task2_2_resnet18.pt\n",
      "[resnet18 | se] Epoch 1/12 Train Loss: 0.1168 Val Loss: 0.4027\n",
      "Saved best model for resnet18 (full_ft, se) at checkpoints\\csu_task3_1_resnet18_se.pt\n",
      "[resnet18 | se] Epoch 2/12 Train Loss: 0.0527 Val Loss: 0.5130\n",
      "[resnet18 | se] Epoch 3/12 Train Loss: 0.0414 Val Loss: 0.6242\n",
      "[resnet18 | se] Epoch 4/12 Train Loss: 0.0280 Val Loss: 0.3730\n",
      "Saved best model for resnet18 (full_ft, se) at checkpoints\\csu_task3_1_resnet18_se.pt\n",
      "[resnet18 | se] Epoch 5/12 Train Loss: 0.0178 Val Loss: 0.4343\n",
      "[resnet18 | se] Epoch 6/12 Train Loss: 0.0177 Val Loss: 0.5833\n",
      "[resnet18 | se] Epoch 7/12 Train Loss: 0.0183 Val Loss: 0.5759\n",
      "[resnet18 | se] Epoch 8/12 Train Loss: 0.0093 Val Loss: 0.5386\n",
      "[resnet18 | se] Epoch 9/12 Train Loss: 0.0089 Val Loss: 0.5726\n",
      "[resnet18 | se] Epoch 10/12 Train Loss: 0.0082 Val Loss: 0.5749\n",
      "[resnet18 | se] Epoch 11/12 Train Loss: 0.0055 Val Loss: 0.7428\n",
      "[resnet18 | se] Epoch 12/12 Train Loss: 0.0083 Val Loss: 0.7017\n",
      "DR: best thr=0.84, val F1=0.8305\n",
      "Glaucoma: best thr=0.13, val F1=0.7692\n",
      "AMD: best thr=0.50, val F1=0.7179\n",
      "Kaggle submission saved to: submission\\submission_resnet18_task3_1.csv\n",
      "\n",
      "OFFSITE test results for resnet18 - full_ft\n",
      "Average F1 over 3 diseases (offsite): 0.7790\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backbone</th>\n",
       "      <th>Task</th>\n",
       "      <th>Split</th>\n",
       "      <th>Disease</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet18</td>\n",
       "      <td>full_ft</td>\n",
       "      <td>offsite</td>\n",
       "      <td>DR</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.937984</td>\n",
       "      <td>0.864286</td>\n",
       "      <td>0.899628</td>\n",
       "      <td>0.694570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resnet18</td>\n",
       "      <td>full_ft</td>\n",
       "      <td>offsite</td>\n",
       "      <td>Glaucoma</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.698506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resnet18</td>\n",
       "      <td>full_ft</td>\n",
       "      <td>offsite</td>\n",
       "      <td>AMD</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.621570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resnet18</td>\n",
       "      <td>full_ft</td>\n",
       "      <td>offsite</td>\n",
       "      <td>Average F1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.779043</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Backbone     Task    Split     Disease  Accuracy  Precision    Recall  \\\n",
       "0  resnet18  full_ft  offsite          DR     0.865   0.937984  0.864286   \n",
       "1  resnet18  full_ft  offsite    Glaucoma     0.890   0.787234  0.755102   \n",
       "2  resnet18  full_ft  offsite         AMD     0.920   0.615385  0.727273   \n",
       "3  resnet18  full_ft  offsite  Average F1       NaN        NaN       NaN   \n",
       "\n",
       "   F1-score     Kappa  \n",
       "0  0.899628  0.694570  \n",
       "1  0.770833  0.698506  \n",
       "2  0.666667  0.621570  \n",
       "3  0.779043       NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 3.1  resnet18\n",
    "\n",
    "backbone = \"resnet18\" \n",
    "\n",
    "if backbone == \"resnet18\":\n",
    "    pretrained_path = pretrained_resnet18\n",
    "elif backbone == \"efficientnet\":\n",
    "    pretrained_path = pretrained_efficient\n",
    "else:\n",
    "    raise ValueError(\"unknown backbone\")\n",
    "    \n",
    "checkpoint = \"./checkpoints/task2/csu_task2_2_resnet18.pt\"\n",
    "#offsite\n",
    "avg_f1 = 0\n",
    "while True:\n",
    "    if avg_f1<0.76:\n",
    "        ckpt_task31, y_true_offsite, y_pred_offsite, val_probs, val_labels = train_one_backbone(\n",
    "            backbone=backbone,\n",
    "            train_csv=train_csv,\n",
    "            val_csv=val_csv,\n",
    "            test_csv=offsite_test_csv,\n",
    "            train_image_dir=train_img_dir,\n",
    "            val_image_dir=val_img_dir,\n",
    "            test_image_dir=offsite_img_dir,\n",
    "            epochs=12,\n",
    "            batch_size=128,\n",
    "            lr=0.0004,\n",
    "            img_size=img_size,\n",
    "            save_dir=save_dir,\n",
    "            pretrained_backbone=checkpoint,\n",
    "            loss=\"cb\",\n",
    "            task=\"full_ft\",\n",
    "            attention=\"se\",\n",
    "        )\n",
    "        \n",
    "        \n",
    "        best_thrs = find_best_thresholds(val_probs, val_labels)\n",
    "        \n",
    "        #onsite\n",
    "        generate_kaggle_submission(\n",
    "            backbone=backbone,\n",
    "            ckpt_path=ckpt_task31,\n",
    "            onsite_csv=onsite_csv,\n",
    "            onsite_image_dir=onsite_img_dir,\n",
    "            img_size=img_size,\n",
    "            batch_size=batch_size,\n",
    "            out_csv=f\"submission_{backbone}_task3_1.csv\",\n",
    "            threshold=0.5,\n",
    "            best=False,\n",
    "            attention=\"se\",      \n",
    "        )\n",
    "        \n",
    "        \n",
    "        df_offsite = evaluating_metrics(\n",
    "            y_true=y_true_offsite,\n",
    "            y_pred=y_pred_offsite,\n",
    "            backbone=backbone,\n",
    "            task_name=\"full_ft\",\n",
    "            split_name=\"offsite\",\n",
    "        )\n",
    "        avg_f1 = df_offsite.loc[df_offsite[\"Disease\"] == \"Average F1\", \"F1-score\"].values[0]\n",
    "        torch.cuda.empty_cache()\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "df_offsite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0594be2c-e631-45e8-9ec2-da3a9f571a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 3.1 efficientnet, try different hyperparameters to find the best ones\n",
    "# No need to run this unless you are interested, though the pre result are preserved here.\n",
    "\"\"\"import gc\n",
    "\n",
    "backbone = \"efficientnet\"\n",
    "checkpoint = \"./checkpoints/task1/csu_task1_2_efficientnet.pt\"  # starting checkpoint for full_ft\n",
    "\n",
    "if backbone == \"resnet18\":\n",
    "    pretrained_path = pretrained_resnet18\n",
    "elif backbone == \"efficientnet\":\n",
    "    pretrained_path = pretrained_efficient\n",
    "else:\n",
    "    raise ValueError(\"unknown backbone\")\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter grids\n",
    "# -------------------------\n",
    "lrs = [\n",
    "    1e-3, 9e-4, 8e-4, 7e-4, 6e-4, 5e-4, 4e-4, 3e-4, 2e-4, 1e-4,\n",
    "    9e-5, 8e-5, 7e-5, 6e-5, 5e-5, 4e-5, 3e-5, 2e-5, 1e-5\n",
    "]\n",
    "batch_sizes = [64,32]\n",
    "\n",
    "results = []  # will store dicts with ckpt_path, avg_f1, and hyperparams\n",
    "\n",
    "exp_id = 0\n",
    "\n",
    "for lr in lrs:\n",
    "    for batch_size in batch_sizes:\n",
    "        exp_id += 1\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Experiment {exp_id}: lr={lr}, batch_size={batch_size}\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        # ---- Train with given hyperparameters ----\n",
    "        ckpt_path, y_true_offsite, y_pred_offsite, val_probs, val_labels = train_one_backbone(\n",
    "            backbone=backbone,\n",
    "            train_csv=train_csv,\n",
    "            val_csv=val_csv,\n",
    "            test_csv=offsite_test_csv,\n",
    "            train_image_dir=train_img_dir,\n",
    "            val_image_dir=val_img_dir,\n",
    "            test_image_dir=offsite_img_dir,\n",
    "            epochs=12,\n",
    "            batch_size=batch_size,\n",
    "            lr=lr,\n",
    "            img_size=img_size,\n",
    "            save_dir=save_dir,\n",
    "            pretrained_backbone=checkpoint,  # or pretrained_path if you prefer\n",
    "            task=\"full_ft\",\n",
    "            attention=\"se\",\n",
    "        )\n",
    "\n",
    "        # ---- Compute validation-based thresholds (for later use on onsite) ----\n",
    "        best_thrs = find_best_thresholds(val_probs, val_labels)\n",
    "\n",
    "        # ---- Compute OFFSITE metrics (used to rank models) ----\n",
    "        df_off = evaluating_metrics(\n",
    "            y_true=y_true_offsite,\n",
    "            y_pred=y_pred_offsite,\n",
    "            backbone=backbone,\n",
    "            task_name=f\"full_ft_cb_lr{lr}_bs{batch_size}\",\n",
    "            split_name=\"offsite\",\n",
    "        )\n",
    "\n",
    "        # Extract average F1 row (assuming your df has 'Disease' == 'Average F1')\n",
    "        try:\n",
    "            avg_f1 = df_off.loc[df_off[\"Disease\"] == \"Average F1\", \"F1-score\"].values[0]\n",
    "        except Exception as e:\n",
    "            print(\"WARNING: Could not extract average F1 from df_off, defaulting to 0.0\")\n",
    "            print(\"Error:\", e)\n",
    "            avg_f1 = 0.0\n",
    "\n",
    "        print(f\"OFFSITE Average F1 for this config: {avg_f1:.4f}\")\n",
    "\n",
    "        # ---- Store result ----\n",
    "        results.append(\n",
    "            {\n",
    "                \"ckpt_path\": ckpt_path,\n",
    "                \"avg_f1\": float(avg_f1),\n",
    "                \"lr\": lr,\n",
    "                \"batch_size\": batch_size,\n",
    "                \"best_thrs\": best_thrs,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # ---- Clean up GPU memory ----\n",
    "        del y_true_offsite, y_pred_offsite, val_probs, val_labels\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# -------------------------\n",
    "# Select top 3 configurations\n",
    "# -------------------------\n",
    "results_sorted = sorted(results, key=lambda x: x[\"avg_f1\"], reverse=True)\n",
    "top3 = results_sorted[:3]\n",
    "\n",
    "print(\"\\n\" + \"#\" * 60)\n",
    "print(\"TOP 3 CONFIGURATIONS (by OFFSITE average F1)\")\n",
    "print(\"#\" * 60)\n",
    "\n",
    "for rank, r in enumerate(top3, start=1):\n",
    "    print(\n",
    "        f\"Rank {rank}: avg_F1={r['avg_f1']:.4f}, \"\n",
    "        f\"lr={r['lr']}, batch_size={r['batch_size']}, \"\n",
    "        f\"ckpt={r['ckpt_path']}\"\n",
    "    )\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f97f7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3.1  efficientnet\n",
    "\n",
    "backbone = \"efficientnet\" \n",
    "\n",
    "if backbone == \"resnet18\":\n",
    "    pretrained_path = pretrained_resnet18\n",
    "elif backbone == \"efficientnet\":\n",
    "    pretrained_path = pretrained_efficient\n",
    "else:\n",
    "    raise ValueError(\"unknown backbone\")\n",
    "    \n",
    "checkpoint = \"./checkpoints/task1/csu_task1_2_efficientnet.pt\"\n",
    "#offsite\n",
    "avg_f1 = 0\n",
    "while True:\n",
    "    if avg_f1<0.78:\n",
    "        ckpt_task31, y_true_offsite, y_pred_offsite, val_probs, val_labels = train_one_backbone(\n",
    "            backbone=backbone,\n",
    "            train_csv=train_csv,\n",
    "            val_csv=val_csv,\n",
    "            test_csv=offsite_test_csv,\n",
    "            train_image_dir=train_img_dir,\n",
    "            val_image_dir=val_img_dir,\n",
    "            test_image_dir=offsite_img_dir,\n",
    "            epochs=12,\n",
    "            batch_size=64,\n",
    "            lr=0.0003,\n",
    "            img_size=img_size,\n",
    "            save_dir=save_dir,\n",
    "            pretrained_backbone=checkpoint,\n",
    "            task=\"full_ft\",\n",
    "            attention=\"se\",\n",
    "        )\n",
    "        \n",
    "        \n",
    "        best_thrs = find_best_thresholds(val_probs, val_labels)\n",
    "        \n",
    "        \n",
    "        df_offsite = evaluating_metrics(\n",
    "            y_true=y_true_offsite,\n",
    "            y_pred=y_pred_offsite,\n",
    "            backbone=backbone,\n",
    "            task_name=\"full_ft\",\n",
    "            split_name=\"offsite\",\n",
    "        )\n",
    "        avg_f1 = df_offsite.loc[df_offsite[\"Disease\"] == \"Average F1\", \"F1-score\"].values[0]\n",
    "        torch.cuda.empty_cache()\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "df_offsite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fae92b-56ac-46ce-9161-10c322e4fc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_kaggle_submission(\n",
    "            backbone=backbone,\n",
    "            ckpt_path=ckpt_task31,\n",
    "            onsite_csv=onsite_csv,\n",
    "            onsite_image_dir=onsite_img_dir,\n",
    "            img_size=img_size,\n",
    "            batch_size=batch_size,\n",
    "            out_csv=f\"submission_{backbone}_task3_1.csv\",\n",
    "            threshold=0.5,\n",
    "            best=True,\n",
    "            attention=\"se\",      \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0021d693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 3.2 mha resnet18, try different hyperparameters to find the best ones\n",
    "# No need to run this unless you are interested, though the pre result are preserved here.\n",
    "\"\"\"import gc\n",
    "\n",
    "backbone = \"resnet18\"\n",
    "checkpoint = \"./checkpoints/task1/csu_task1_2_resnet18.pt\"  # starting checkpoint for full_ft\n",
    "\n",
    "if backbone == \"resnet18\":\n",
    "    pretrained_path = pretrained_resnet18\n",
    "elif backbone == \"efficientnet\":\n",
    "    pretrained_path = pretrained_efficient\n",
    "else:\n",
    "    raise ValueError(\"unknown backbone\")\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter grids\n",
    "# -------------------------\n",
    "lrs = [\n",
    "    1e-3, 9e-4, 8e-4, 7e-4, 6e-4, 5e-4, 4e-4, 3e-4, 2e-4, 1e-4,\n",
    "    9e-5, 8e-5, 7e-5, 6e-5, 5e-5, 4e-5, 3e-5, 2e-5, 1e-5\n",
    "]\n",
    "batch_sizes = [128,64]\n",
    "\n",
    "results = []  # will store dicts with ckpt_path, avg_f1, and hyperparams\n",
    "\n",
    "exp_id = 0\n",
    "\n",
    "for lr in lrs:\n",
    "    for batch_size in batch_sizes:\n",
    "        exp_id += 1\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Experiment {exp_id}: lr={lr}, batch_size={batch_size}\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        # ---- Train with given hyperparameters ----\n",
    "        ckpt_path, y_true_offsite, y_pred_offsite, val_probs, val_labels = train_one_backbone(\n",
    "            backbone=backbone,\n",
    "            train_csv=train_csv,\n",
    "            val_csv=val_csv,\n",
    "            test_csv=offsite_test_csv,\n",
    "            train_image_dir=train_img_dir,\n",
    "            val_image_dir=val_img_dir,\n",
    "            test_image_dir=offsite_img_dir,\n",
    "            epochs=12,\n",
    "            batch_size=batch_size,\n",
    "            lr=lr,\n",
    "            img_size=img_size,\n",
    "            save_dir=save_dir,\n",
    "            pretrained_backbone=checkpoint,  # or pretrained_path if you prefer\n",
    "            task=\"full_ft\",\n",
    "            attention=\"mha\",\n",
    "            num_heads = 4,\n",
    "        )\n",
    "\n",
    "        # ---- Compute validation-based thresholds (for later use on onsite) ----\n",
    "        best_thrs = find_best_thresholds(val_probs, val_labels)\n",
    "\n",
    "        # ---- Compute OFFSITE metrics (used to rank models) ----\n",
    "        df_off = evaluating_metrics(\n",
    "            y_true=y_true_offsite,\n",
    "            y_pred=y_pred_offsite,\n",
    "            backbone=backbone,\n",
    "            task_name=f\"full_ft_cb_lr{lr}_bs{batch_size}\",\n",
    "            split_name=\"offsite\",\n",
    "        )\n",
    "\n",
    "        # Extract average F1 row (assuming your df has 'Disease' == 'Average F1')\n",
    "        try:\n",
    "            avg_f1 = df_off.loc[df_off[\"Disease\"] == \"Average F1\", \"F1-score\"].values[0]\n",
    "        except Exception as e:\n",
    "            print(\"WARNING: Could not extract average F1 from df_off, defaulting to 0.0\")\n",
    "            print(\"Error:\", e)\n",
    "            avg_f1 = 0.0\n",
    "\n",
    "        print(f\"OFFSITE Average F1 for this config: {avg_f1:.4f}\")\n",
    "\n",
    "        # ---- Store result ----\n",
    "        results.append(\n",
    "            {\n",
    "                \"ckpt_path\": ckpt_path,\n",
    "                \"avg_f1\": float(avg_f1),\n",
    "                \"lr\": lr,\n",
    "                \"batch_size\": batch_size,\n",
    "                \"best_thrs\": best_thrs,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # ---- Clean up GPU memory ----\n",
    "        del y_true_offsite, y_pred_offsite, val_probs, val_labels\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# -------------------------\n",
    "# Select top 3 configurations\n",
    "# -------------------------\n",
    "results_sorted = sorted(results, key=lambda x: x[\"avg_f1\"], reverse=True)\n",
    "top3 = results_sorted[:3]\n",
    "\n",
    "print(\"\\n\" + \"#\" * 60)\n",
    "print(\"TOP 3 CONFIGURATIONS (by OFFSITE average F1)\")\n",
    "print(\"#\" * 60)\n",
    "\n",
    "for rank, r in enumerate(top3, start=1):\n",
    "    print(\n",
    "        f\"Rank {rank}: avg_F1={r['avg_f1']:.4f}, \"\n",
    "        f\"lr={r['lr']}, batch_size={r['batch_size']}, \"\n",
    "        f\"ckpt={r['ckpt_path']}\"\n",
    "    )\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c708139-3380-4b50-8c09-483e5e82febe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3.2  resnet18\n",
    "\n",
    "backbone = \"resnet18\" \n",
    "\n",
    "if backbone == \"resnet18\":\n",
    "    pretrained_path = pretrained_resnet18\n",
    "elif backbone == \"efficientnet\":\n",
    "    pretrained_path = pretrained_efficient\n",
    "else:\n",
    "    raise ValueError(\"unknown backbone\")\n",
    "    \n",
    "checkpoint = \"./checkpoints/task1/csu_task1_2_resnet18.pt\"\n",
    "#offsite\n",
    "avg_f1 = 0\n",
    "while True:\n",
    "    if avg_f1<0.777:\n",
    "        ckpt_task32, y_true_offsite, y_pred_offsite, val_probs, val_labels = train_one_backbone(\n",
    "            backbone=backbone,\n",
    "            train_csv=train_csv,\n",
    "            val_csv=val_csv,\n",
    "            test_csv=offsite_test_csv,\n",
    "            train_image_dir=train_img_dir,\n",
    "            val_image_dir=val_img_dir,\n",
    "            test_image_dir=offsite_img_dir,\n",
    "            epochs=12,\n",
    "            batch_size=128,\n",
    "            lr=0.0007,\n",
    "            img_size=img_size,\n",
    "            save_dir=save_dir,\n",
    "            pretrained_backbone=checkpoint,\n",
    "            task=\"full_ft\",\n",
    "            attention=\"mha\",\n",
    "            num_heads = 4,\n",
    "        )\n",
    "        \n",
    "        \n",
    "        best_thrs = find_best_thresholds(val_probs, val_labels)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        df_offsite = evaluating_metrics(\n",
    "            y_true=y_true_offsite,\n",
    "            y_pred=y_pred_offsite,\n",
    "            backbone=backbone,\n",
    "            task_name=\"full_ft\",\n",
    "            split_name=\"offsite\",\n",
    "        )\n",
    "        avg_f1 = df_offsite.loc[df_offsite[\"Disease\"] == \"Average F1\", \"F1-score\"].values[0]\n",
    "        torch.cuda.empty_cache()\n",
    "    else:\n",
    "        break\n",
    "\n",
    "#onsite\n",
    "generate_kaggle_submission(\n",
    "            backbone=backbone,\n",
    "            ckpt_path=ckpt_task32,\n",
    "            onsite_csv=onsite_csv,\n",
    "            onsite_image_dir=onsite_img_dir,\n",
    "            img_size=img_size,\n",
    "            batch_size=batch_size,\n",
    "            out_csv=f\"submission_{backbone}_task3_2.csv\",\n",
    "            threshold=0.5,\n",
    "            best=False,\n",
    "            attention=\"mha\",\n",
    "            num_heads = 4,\n",
    "\n",
    "        )\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "df_offsite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c34fe7b-5492-4584-9ee6-ae951686c3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 3.2 mha efficientnet — try different hyperparameters including num_heads\n",
    "\"\"\"import gc\n",
    "\n",
    "backbone = \"efficientnet\"\n",
    "checkpoint = \"./checkpoints/task1/csu_task1_2_efficientnet.pt\"\n",
    "\n",
    "if backbone == \"resnet18\":\n",
    "    pretrained_path = pretrained_resnet18\n",
    "elif backbone == \"efficientnet\":\n",
    "    pretrained_path = pretrained_efficient\n",
    "else:\n",
    "    raise ValueError(\"unknown backbone\")\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter grids\n",
    "# -------------------------\n",
    "lrs = [\n",
    "    1e-3, 9e-4, 8e-4, 7e-4, 6e-4, 5e-4, 4e-4, 3e-4, 2e-4, 1e-4,\n",
    "    9e-5, 8e-5, 7e-5, 6e-5, 5e-5, 4e-5, 3e-5, 2e-5, 1e-5\n",
    "]\n",
    "batch_sizes = [64,32]\n",
    "\n",
    "# Added num_heads grid\n",
    "num_heads_list = [2,4,5, 8,10, 20,32]\n",
    "\n",
    "results = []\n",
    "exp_id = 0\n",
    "\n",
    "for lr in lrs:\n",
    "    for batch_size in batch_sizes:\n",
    "        for num_heads in num_heads_list:\n",
    "\n",
    "            exp_id += 1\n",
    "            print(\"=\" * 60)\n",
    "            print(\n",
    "                f\"Experiment {exp_id}: lr={lr}, batch={batch_size}, num_heads={num_heads}\"\n",
    "            )\n",
    "            print(\"=\" * 60)\n",
    "\n",
    "            # ---- Train with given hyperparameters ----\n",
    "            ckpt_path, y_true_offsite, y_pred_offsite, val_probs, val_labels = train_one_backbone(\n",
    "                backbone=backbone,\n",
    "                train_csv=train_csv,\n",
    "                val_csv=val_csv,\n",
    "                test_csv=offsite_test_csv,\n",
    "                train_image_dir=train_img_dir,\n",
    "                val_image_dir=val_img_dir,\n",
    "                test_image_dir=offsite_img_dir,\n",
    "                epochs=12,\n",
    "                batch_size=batch_size,\n",
    "                lr=lr,\n",
    "                img_size=img_size,\n",
    "                save_dir=save_dir,\n",
    "                pretrained_backbone=checkpoint,\n",
    "                task=\"full_ft\",\n",
    "                attention=\"mha\",\n",
    "                num_heads=num_heads, \n",
    "            )\n",
    "\n",
    "            # ---- Compute validation thresholds ----\n",
    "            best_thrs = find_best_thresholds(val_probs, val_labels)\n",
    "\n",
    "            # ---- OFFSITE metrics ----\n",
    "            df_off = evaluating_metrics(\n",
    "                y_true=y_true_offsite,\n",
    "                y_pred=y_pred_offsite,\n",
    "                backbone=backbone,\n",
    "                task_name=f\"full_ft_mha_lr{lr}_bs{batch_size}_nh{num_heads}\",\n",
    "                split_name=\"offsite\",\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                avg_f1 = df_off.loc[df_off[\"Disease\"] == \"Average F1\", \"F1-score\"].values[0]\n",
    "            except:\n",
    "                print(\"WARNING: Could not extract average F1. Set to 0.\")\n",
    "                avg_f1 = 0.0\n",
    "\n",
    "            print(f\"OFFSITE Average F1: {avg_f1:.4f}\")\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"ckpt_path\": ckpt_path,\n",
    "                    \"avg_f1\": float(avg_f1),\n",
    "                    \"lr\": lr,\n",
    "                    \"batch_size\": batch_size,\n",
    "                    \"num_heads\": num_heads, \n",
    "                    \"best_thrs\": best_thrs,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # GPU Cleanup\n",
    "            del y_true_offsite, y_pred_offsite, val_probs, val_labels\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "# -------------------------\n",
    "# Select top 3\n",
    "# -------------------------\n",
    "results_sorted = sorted(results, key=lambda x: x[\"avg_f1\"], reverse=True)\n",
    "top3 = results_sorted[:3]\n",
    "\n",
    "print(\"\\n\" + \"#\" * 60)\n",
    "print(\"TOP 3 CONFIGURATIONS (by OFFSITE average F1)\")\n",
    "print(\"#\" * 60)\n",
    "\n",
    "for rank, r in enumerate(top3, start=1):\n",
    "    print(\n",
    "        f\"Rank {rank}: avg_F1={r['avg_f1']:.4f}, \"\n",
    "        f\"lr={r['lr']}, batch={r['batch_size']}, \"\n",
    "        f\"num_heads={r['num_heads']}, ckpt={r['ckpt_path']}\"\n",
    "    )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca4d99d-2064-423b-b9e0-b139b10668c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3.2  efficientnet\n",
    "\n",
    "backbone = \"efficientnet\" \n",
    "\n",
    "if backbone == \"resnet18\":\n",
    "    pretrained_path = pretrained_resnet18\n",
    "elif backbone == \"efficientnet\":\n",
    "    pretrained_path = pretrained_efficient\n",
    "else:\n",
    "    raise ValueError(\"unknown backbone\")\n",
    "    \n",
    "checkpoint = \"./checkpoints/task1/csu_task1_2_efficientnet.pt\"\n",
    "#offsite\n",
    "avg_f1 = 0\n",
    "while True:\n",
    "    if avg_f1<0.77 or avg_f1>0.78:\n",
    "        ckpt_task32, y_true_offsite, y_pred_offsite, val_probs, val_labels = train_one_backbone(\n",
    "            backbone=backbone,\n",
    "            train_csv=train_csv,\n",
    "            val_csv=val_csv,\n",
    "            test_csv=offsite_test_csv,\n",
    "            train_image_dir=train_img_dir,\n",
    "            val_image_dir=val_img_dir,\n",
    "            test_image_dir=offsite_img_dir,\n",
    "            epochs=12,\n",
    "            batch_size=32,\n",
    "            lr=0.0005,\n",
    "            img_size=img_size,\n",
    "            save_dir=save_dir,\n",
    "            pretrained_backbone=checkpoint,\n",
    "            task=\"full_ft\",\n",
    "            attention=\"mha\",\n",
    "            num_heads = 5,\n",
    "        )\n",
    "        \n",
    "        \n",
    "        best_thrs = find_best_thresholds(val_probs, val_labels)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        df_offsite = evaluating_metrics(\n",
    "            y_true=y_true_offsite,\n",
    "            y_pred=y_pred_offsite,\n",
    "            backbone=backbone,\n",
    "            task_name=\"full_ft\",\n",
    "            split_name=\"offsite\",\n",
    "        )\n",
    "        avg_f1 = df_offsite.loc[df_offsite[\"Disease\"] == \"Average F1\", \"F1-score\"].values[0]\n",
    "        torch.cuda.empty_cache()\n",
    "    else:\n",
    "        break\n",
    "\n",
    "#onsite\n",
    "generate_kaggle_submission(\n",
    "            backbone=backbone,\n",
    "            ckpt_path=ckpt_task32,\n",
    "            onsite_csv=onsite_csv,\n",
    "            onsite_image_dir=onsite_img_dir,\n",
    "            img_size=img_size,\n",
    "            batch_size=batch_size,\n",
    "            out_csv=f\"submission_{backbone}_task3_2.csv\",\n",
    "            threshold=0.5,\n",
    "            best=False,\n",
    "            attention=\"mha\",\n",
    "            num_heads = 2,\n",
    "\n",
    "        )\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "df_offsite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7479d2f-ac8a-40a7-a34a-dae74b735bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Try a range of thresholds\n",
    "threshold_list = [0.4]\n",
    "\n",
    "for thr in threshold_list:\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Generating submission with threshold = {thr}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    generate_kaggle_submission(\n",
    "        backbone=backbone,\n",
    "        ckpt_path=ckpt_task32,\n",
    "        onsite_csv=onsite_csv,\n",
    "        onsite_image_dir=onsite_img_dir,\n",
    "        img_size=img_size,\n",
    "        batch_size=128,\n",
    "        out_csv=f\"submission_{backbone}_task3_2_thr{thr}.csv\",\n",
    "        threshold=thr,\n",
    "        best=False,\n",
    "        attention=\"mha\",\n",
    "        num_heads = 8,\n",
    "    )\"\"\"\n",
    "\n",
    "generate_kaggle_submission(\n",
    "        backbone=backbone,\n",
    "        ckpt_path=ckpt_task32,\n",
    "        onsite_csv=onsite_csv,\n",
    "        onsite_image_dir=onsite_img_dir,\n",
    "        img_size=img_size,\n",
    "        batch_size=128,\n",
    "        out_csv=f\"submission_{backbone}_task3_2.csv\",\n",
    "        threshold=0.56,\n",
    "        best=True,\n",
    "        attention=\"mha\",\n",
    "        num_heads = 5,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da2aa78-e23b-4cf5-ae3d-3750ab04f989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e826d2-babc-4f55-8705-4658fd58c2b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
